{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy5adee5GC8a"
      },
      "source": [
        "# huggingface - pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install transformers datasets xformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install transformers datasets xformers -c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BNG3RveGHBS"
      },
      "source": [
        "## pipeline - 감정 분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Pjf48SG23r"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "results = classifier(\"We are very happy.\")\n",
        "print(results)\n",
        "\n",
        "results = classifier([\"We are very happy.\", \"We hope you don't hate it.\"])\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4hNfH2_xOSK"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"matthewburke/korean_sentiment\")\n",
        "classifier([\"괜찮은데?\", \"생각보단 별로네\", \"그저그래\", \"영화 재미있었다\", \"평범했어\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcJwMTaCw2a8"
      },
      "source": [
        "## pipeline - 텍스트 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK0gsDaTw06X"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\")\n",
        "\n",
        "result = generator(\"I'm pregnant\", max_length=1000)\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUkMH1w6xIRb"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 모델 로딩\n",
        "generator = pipeline(\"text-generation\", max_length=1000,\n",
        "                     model=\"skt/kogpt2-base-v2\")\n",
        "\n",
        "# 모델 이용\n",
        "result = generator(\"KT 에이블스쿨은 최고야.\")\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eZI_VCE5kMk"
      },
      "source": [
        "## pipeline - 이미지 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXDFLN-E5gzl"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "from transformers import pipeline\n",
        "\n",
        "img = \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\"\n",
        "img2 = 'https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/beignets-task-guide.png'\n",
        "\n",
        "# 이미지 분류\n",
        "classifier = pipeline(\"image-classification\")\n",
        "result = classifier(img2)\n",
        "print(result)\n",
        "\n",
        "# 이미지 설명\n",
        "caption = pipeline(\"image-to-text\")\n",
        "result = caption(img2)\n",
        "print(result)\n",
        "\n",
        "# 이미지 보기\n",
        "Image(img2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChKcHNtsLSVS"
      },
      "source": [
        "## pipeline - 음성 인식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install soundfile\n",
        "pip install librosa\n",
        "pip install torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDnWgw4jKiM1"
      },
      "outputs": [],
      "source": [
        "# 오디오 데이터셋 로딩\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n",
        "print(dataset[0]['transcription'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65k6YndeLEGh"
      },
      "outputs": [],
      "source": [
        "# 오디오 파일 재생\n",
        "from IPython.display import Audio\n",
        "Audio(dataset[0][\"audio\"]['path'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pQkeVAGHycH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# 모델 로딩\n",
        "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"facebook/wav2vec2-base-960h\")\n",
        "\n",
        "# 모델 사용\n",
        "result = speech_recognizer(dataset[0][\"audio\"])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYdgS0JxPOA8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "from IPython.display import Audio\n",
        "\n",
        "# 오디오 데이터셋 로딩\n",
        "dataset = load_dataset(\"PolyAI/minds14\", name=\"ko-KR\", split=\"train\")\n",
        "print(dataset)\n",
        "\n",
        "# 모델 로딩\n",
        "speech_recognizer = pipeline(\"automatic-speech-recognition\", model=\"Hyuk/wav2vec2-korean-v2\")\n",
        "\n",
        "# 모델 사용\n",
        "result = speech_recognizer(dataset[1][\"audio\"])\n",
        "print(result)\n",
        "\n",
        "# 오디오 파일 재생\n",
        "Audio(dataset[1][\"audio\"]['path'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTUiCktelKNC"
      },
      "source": [
        "## gradio chatbot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eo4Nnlt89cF9"
      },
      "outputs": [],
      "source": [
        "# pip install gradio \n",
        "# !pip install peft -q\n",
        "# !pip install sentencepiece -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "def greet(sentence):\n",
        "    classifier = pipeline(\"sentiment-analysis\", \"matthewburke/korean_sentiment\")\n",
        "    result = classifier(sentence)\n",
        "    d = {\n",
        "        'LABEL_1': '긍정',\n",
        "        'LABEL_0': '부정'\n",
        "    }\n",
        "\n",
        "    return f\"{sentence}\\n 이 문장이 {d[result[0]['label']]} 일 확률은 {result[0]['score'] * 100}%\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    print(name)\n",
        "    return 'Hello ' + name + '!'    \n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs='text', outputs='text')\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-HO89f6yP2uw"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat(msg, history):\n",
        "    history.append((msg, \"안녕. 반가워\"))\n",
        "    return \"\", history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    msg.submit(chat, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NuBBUhZzRa3o"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", max_length=1000,\n",
        "                     model=\"EasthShin/Youth_Chatbot_Kogpt2-base\")\n",
        "\n",
        "prompt = \"안녕\"\n",
        "result = generator(prompt)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4F5tam_LG-Q"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", max_length=1000, model=\"EasthShin/Youth_Chatbot_Kogpt2-base\")\n",
        "\n",
        "def chat(msg, history):\n",
        "    prompt = '\\n'.join([f\"유저: {h[0]}\\n챗봇: {h[1]}\" for h in history[-3:]])\n",
        "    prompt = f\"{prompt}\\n유저: {msg}\\n챗봇: \"\n",
        "\n",
        "    gen_text = generator(prompt)[0]['generated_text']\n",
        "    history.append((msg, gen_text[len(prompt):]))\n",
        "\n",
        "    return \"\", history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    msg.submit(chat, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNSNVWvOcsxn"
      },
      "source": [
        "# OpenAI 챗봇\n",
        "https://openai.com/research/instruction-following"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrE10Ltkcwjv"
      },
      "outputs": [],
      "source": [
        "pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPdkfsk5c3Lp"
      },
      "source": [
        "## gpt3 api\n",
        "- openai.Completion.create\n",
        "  - model\n",
        "  - prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EkahPjxQcx96"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Hugging Face와 OpenAI를 비교해 줘.\",\n",
        "    temperature=0.7,\n",
        "    max_tokens=1000\n",
        ")\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZA7Oe0Ic5zj"
      },
      "source": [
        "# chatgpt api\n",
        "- openai.ChatCompletion.create\n",
        "  - model\n",
        "  - messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 지피티 챗 모델\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"system\",\n",
        "      \"content\": \"i want the basic python code\"\n",
        "    }\n",
        "  ],\n",
        "  temperature=1,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 지피티 mode=complete\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=\"마이클 잭슨\",\n",
        "  temperature=1,\n",
        "  max_tokens=256,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n",
        "print(response.choices[0].text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KnWCJQVSJal-"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "response = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "        {\"role\": \"system\", \"content\": \"TRPG 게임의 마스터 역할. 흥미로운 게임을 진행할 수 있도록 도와준다.\"},\n",
        "        {\"role\": \"user\", \"content\": \"나에게 먼저 질문을 해서 게임을 시작해줘.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"당신이 플레이할 캐릭터의 이름과 직업. 나이를 말씀해 주세요.\"},\n",
        "        {\"role\": \"user\", \"content\": \"블랙듀, 20살. 남성. 프로그래머\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fX9Hk5esdDy7"
      },
      "source": [
        "## with gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_tOghj_dHcg"
      },
      "outputs": [],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JaopYbNxdALC"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "def 텍스트생성(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"'{prompt}' 이 문장을 영어로 번역해줘\",\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    return response['choices'][0]['text'].strip()\n",
        "\n",
        "demo = gr.Interface(fn=텍스트생성, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "def 텍스트생성(prompt):\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=f\"'{prompt}' 삼행시를 지어줘\",\n",
        "        temperature=0.7,\n",
        "        max_tokens=1024,\n",
        "    )\n",
        "    return response['choices'][0]['text'].strip()\n",
        "\n",
        "demo = gr.Interface(fn=텍스트생성, inputs=\"text\", outputs=\"text\")\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEefoEswdJQH"
      },
      "outputs": [],
      "source": [
        "def make_message(msg, history):\n",
        "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "    for h in history[-10:]:\n",
        "        messages.append({\"role\": \"user\", \"content\": h[0]})\n",
        "        messages.append({\"role\": \"assistant\", \"content\": h[1]})\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": msg})\n",
        "    return messages\n",
        "\n",
        "history = [\n",
        "    (\"안녕\", \"안녕하세요. 무엇을 도와드릴까요?\"),\n",
        "]\n",
        "make_message(\"매수 타이밍 좀...\", history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8-XvxsfdLDE"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "def chat(msg, history):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=make_message(msg, history)\n",
        "    )\n",
        "    history.append((msg, response['choices'][0]['message']['content']))\n",
        "    return \"\", history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "\n",
        "    msg.submit(chat, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch(debug=True, share=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import openai\n",
        "\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "\n",
        "messages=[\n",
        "    {\"role\": \"system\", \"content\": \"넌 이제부터 내 오랜 친구야\"},\n",
        "]\n",
        "\n",
        "def chat(msg, history):\n",
        "    messages.append({\"role\": \"user\", \"content\": msg})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"system\", \"content\": \"넌 이제부터 내 오랜 친구야\"}, *messages[10:]],\n",
        "        temperature = 1,\n",
        "        max_tokens=512\n",
        "    )\n",
        "    messages.append({\"role\":\"assistant\", \"content\":response.choices[0].message['content']})\n",
        "    print(messages)\n",
        "    \n",
        "    history.append((msg, response.choices[0].message['content']))\n",
        "    return \"\", history\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox()\n",
        "    send = gr.Button('Send')\n",
        "    clear = gr.ClearButton([msg, chatbot])\n",
        "    msg.submit(chat, [msg, chatbot], [msg, chatbot])\n",
        "    send.click(chat, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch(share=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "# 토큰화 함수\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"taeminlee/kogpt2\")\n",
        "# 다음 단어 함수\n",
        "model = GPT2LMHeadModel.from_pretrained(\"taeminlee/kogpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 2656, 47485,  1681, 47441, 10635]])"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"아들아 너는 계획이\"\n",
        "tokens = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ -0.8730,   7.6543, -11.9663,  ...,  -7.1661,  -0.3533,  -2.2992],\n",
              "       grad_fn=<SliceBackward0>)"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outputs = model(tokens)[0][0, -1, :] # 모든 토큰들의 확률값\n",
        "outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(105)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token = outputs.argmax(-1) # 가장 높은 확률의 토큰\n",
        "token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'있'"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "decoded = tokenizer.decode(token)\n",
        "decoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[ 2656, 47485,  1681, 47441, 10635,   148]])"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "# 토큰화 함수\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"taeminlee/kogpt2\")\n",
        "# 다음 단어 함수\n",
        "model = GPT2LMHeadModel.from_pretrained(\"taeminlee/kogpt2\")\n",
        "text = \"아들아 너는 계획이 다\"\n",
        "tokens = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\transformers\\generation\\utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 2656, 47485,  1681, 47441, 10635,   148,   605,     1,     0,   155,\n",
            "          872,  7892,  8274,   605,     1,     0,   155,   872,  7892,  8274])\n",
            "아들아 너는 계획이 다 있어</s><s> 나 지금 집에 가고 있어</s><s> 나 지금 집에 가고\n"
          ]
        }
      ],
      "source": [
        "outputs = model.generate(tokens)\n",
        "print(outputs[0])\n",
        "generated_text = tokenizer.decode(outputs[0])\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
