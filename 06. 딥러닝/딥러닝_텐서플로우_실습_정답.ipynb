{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNr2tQvUu1dm"
      },
      "source": [
        "# 텐서플로우 - 표"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCcdJK04KvPW"
      },
      "source": [
        "## 첫번째 딥러닝 - 레모네이드 판매 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4hU9rb2WJkdv"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>온도</th>\n",
              "      <th>판매량</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   온도  판매량\n",
              "0  20   40\n",
              "1  21   42"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터를 준비합니다.\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/lemonade.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cCkctOvKLKtl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 1) (6, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train = df[['온도']]\n",
        "y_train = df[['판매량']]\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eQvAw26kLZwC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 모델을 준비합니다.\n",
        "X = tf.keras.Input(shape=[1])\n",
        "Y = tf.keras.layers.Dense(1)(X)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fGeNTbtgROXd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3120e-04\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3099e-04\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.3060e-04\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3024e-04\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2993e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1ce76e7b790>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터로 모델을 학습합니다.\n",
        "model.fit(x_train, y_train, epochs=1000, verbose=0)\n",
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zU8DwVleRY2j"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 89ms/step\n",
            "[[30.067976]]\n"
          ]
        }
      ],
      "source": [
        "# 모델을 이용합니다.\n",
        "y_pred = model.predict([[15]])\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QwUwBJb4RvLU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[1.9895359]], dtype=float32), array([0.22493668], dtype=float32)]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VYre2lCEXFNc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30.322062749999997\n"
          ]
        }
      ],
      "source": [
        "온도 = 15\n",
        "판매량 = 1.9593028 * 온도 + 0.93252075\n",
        "print(판매량)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_JT3TXLYJpe"
      },
      "source": [
        "## 두번째 딥러닝 - 보스턴 집값 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I-WKUMggXRwB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
            "       'ptratio', 'b', 'lstat', 'medv'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>crim</th>\n",
              "      <th>zn</th>\n",
              "      <th>indus</th>\n",
              "      <th>chas</th>\n",
              "      <th>nox</th>\n",
              "      <th>rm</th>\n",
              "      <th>age</th>\n",
              "      <th>dis</th>\n",
              "      <th>rad</th>\n",
              "      <th>tax</th>\n",
              "      <th>ptratio</th>\n",
              "      <th>b</th>\n",
              "      <th>lstat</th>\n",
              "      <th>medv</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1</td>\n",
              "      <td>296</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.9</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2</td>\n",
              "      <td>242</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.9</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
              "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
              "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
              "\n",
              "       b  lstat  medv  \n",
              "0  396.9   4.98  24.0  \n",
              "1  396.9   9.14  21.6  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터를 준비합니다.\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(df.columns)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "gSPxRFlcZsv-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(506, 13) (506, 1)\n"
          ]
        }
      ],
      "source": [
        "x_train = df[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis',\n",
        "              'rad', 'tax','ptratio', 'b', 'lstat']]\n",
        "y_train = df[['medv']]\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g0pul1UrZ7tT"
      },
      "outputs": [],
      "source": [
        "# 모델을 준비합니다.\n",
        "X = tf.keras.Input(shape=[13])\n",
        "Y = tf.keras.layers.Dense(1)(X)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HSknTwuVaXSh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.5846\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.3972\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.0635\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 27.6980\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 27.2949\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 26.8051\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.5553\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.1188\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.0853\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.3631\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1ce781ab7d0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델을 학습합니다.\n",
        "model.fit(x_train, y_train, epochs=1000, verbose=0)\n",
        "model.fit(x_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fNzI9LmgaYWY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   medv\n",
            "0  24.0\n",
            "1  21.6\n",
            "2  34.7\n",
            "3  33.4\n",
            "4  36.2\n",
            "1/1 [==============================] - 0s 42ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[29.33423 ],\n",
              "       [24.837648],\n",
              "       [30.24577 ],\n",
              "       [29.675491],\n",
              "       [28.984081]], dtype=float32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델을 이용합니다.\n",
        "print(y_train[0:5])\n",
        "model.predict(x_train[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M0p6JPsFa2Zl"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.08662984],\n",
              "        [ 0.07971437],\n",
              "        [-0.06368691],\n",
              "        [ 3.5433893 ],\n",
              "        [ 1.9437267 ],\n",
              "        [ 3.6211174 ],\n",
              "        [ 0.02226269],\n",
              "        [-0.87990546],\n",
              "        [ 0.14016585],\n",
              "        [-0.00899231],\n",
              "        [ 0.12153991],\n",
              "        [ 0.01651801],\n",
              "        [-0.6076491 ]], dtype=float32),\n",
              " array([2.4718444], dtype=float32)]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQhFkTS4lWkA"
      },
      "source": [
        "## 세번째 딥러닝 - 아이리스 품종 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "maRK67q8e2PJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종'], dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "      <th>품종</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭      품종\n",
              "0   5.1  3.5    1.4   0.2  setosa\n",
              "1   4.9  3.0    1.4   0.2  setosa"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터를 준비합니다.\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(df.columns)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WN7VYCZ7la94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭', '품종_setosa', '품종_versicolor',\n",
            "       '품종_virginica'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>꽃잎길이</th>\n",
              "      <th>꽃잎폭</th>\n",
              "      <th>꽃받침길이</th>\n",
              "      <th>꽃받침폭</th>\n",
              "      <th>품종_setosa</th>\n",
              "      <th>품종_versicolor</th>\n",
              "      <th>품종_virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   꽃잎길이  꽃잎폭  꽃받침길이  꽃받침폭  품종_setosa  품종_versicolor  품종_virginica\n",
              "0   5.1  3.5    1.4   0.2          1              0             0\n",
              "1   4.9  3.0    1.4   0.2          1              0             0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_onehot = pd.get_dummies(df)\n",
        "print(df_onehot.columns)\n",
        "df_onehot.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZX-JSqsslgqE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(150, 4) (150, 3)\n"
          ]
        }
      ],
      "source": [
        "x_train = df_onehot[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
        "y_train = df_onehot[['품종_setosa', '품종_versicolor', '품종_virginica']]\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "LfPta1HzlvhD"
      },
      "outputs": [],
      "source": [
        "# 모델을 완성합니다\n",
        "X = tf.keras.Input(shape=[4])\n",
        "Y = tf.keras.layers.Dense(3, activation='softmax')(X)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "# activation이 sigmoid일 때는 loss는 binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ATqMV_oTvFmg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5/5 [==============================] - 0s 0s/step - loss: 0.2694 - accuracy: 0.9800\n",
            "Epoch 2/5\n",
            "5/5 [==============================] - 0s 4ms/step - loss: 0.2680 - accuracy: 0.9733\n",
            "Epoch 3/5\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2680 - accuracy: 0.9800\n",
            "Epoch 4/5\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2677 - accuracy: 0.9800\n",
            "Epoch 5/5\n",
            "5/5 [==============================] - 0s 1ms/step - loss: 0.2667 - accuracy: 0.9800\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1ce783eb790>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델을 학습합니다.\n",
        "model.fit(x_train, y_train, epochs=500, verbose=0)\n",
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ygm2Cc9NvGgF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[1.6924298e-04, 3.2654580e-01, 6.7328495e-01],\n",
              "       [2.2887078e-04, 3.7558788e-01, 6.2418324e-01],\n",
              "       [3.5091964e-04, 3.5217306e-01, 6.4747608e-01],\n",
              "       [1.8279835e-04, 2.1057099e-01, 7.8924620e-01],\n",
              "       [5.7899422e-04, 3.1181288e-01, 6.8760812e-01]], dtype=float32)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델을 이용합니다.\n",
        "model.predict(x_train[-5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "iXRLAtk9vHrB"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>품종_setosa</th>\n",
              "      <th>품종_versicolor</th>\n",
              "      <th>품종_virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     품종_setosa  품종_versicolor  품종_virginica\n",
              "145          0              0             1\n",
              "146          0              0             1\n",
              "147          0              0             1\n",
              "148          0              0             1\n",
              "149          0              0             1"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "y-IBlVLZwrRG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[-0.26905823, -0.24039608, -1.0606489 ],\n",
              "        [ 1.7993655 , -0.3207907 , -0.47447488],\n",
              "        [-1.914464  , -0.18147764,  1.0635427 ],\n",
              "        [-2.05109   ,  0.10870302,  1.0376681 ]], dtype=float32),\n",
              " array([ 1.0828182,  0.8371888, -1.093192 ], dtype=float32)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkUFbX24UkHH"
      },
      "source": [
        "## 네번째 딥러닝 - 진짜 딥러닝 히든 레이어"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "22y8JO2VUsN6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MUqTWFAIxZWI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
            "       'ptratio', 'b', 'lstat', 'medv'],\n",
            "      dtype='object')\n",
            "(506, 14)\n",
            "(506, 13) (506, 1)\n"
          ]
        }
      ],
      "source": [
        "# 데이터 준비\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(df.columns)\n",
        "print(df.shape)\n",
        "\n",
        "x_train = df[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax',\n",
        "       'ptratio', 'b', 'lstat']]\n",
        "y_train = df[['medv']]\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TlnjTcW3Utua"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 13)]              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               1792      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1921 (7.50 KB)\n",
            "Trainable params: 1921 (7.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 모델 준비\n",
        "X = tf.keras.Input(shape=[13])\n",
        "H = tf.keras.layers.Dense(128, activation='swish')(X)\n",
        "# H = tf.keras.layers.Dense(16, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(1)(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "V1Z9FuJUUvBQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 1ms/step - loss: 485.6178\n",
            "Epoch 2/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 103.6330\n",
            "Epoch 3/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 73.6204\n",
            "Epoch 4/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 88.8155\n",
            "Epoch 5/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 85.7135\n",
            "Epoch 6/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 76.2443\n",
            "Epoch 7/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 77.8768\n",
            "Epoch 8/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 81.6111\n",
            "Epoch 9/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 57.6932\n",
            "Epoch 10/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 59.4734\n",
            "Epoch 11/300\n",
            "16/16 [==============================] - 0s 860us/step - loss: 74.8815\n",
            "Epoch 12/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 61.6382\n",
            "Epoch 13/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 68.4355\n",
            "Epoch 14/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 65.8804\n",
            "Epoch 15/300\n",
            "16/16 [==============================] - 0s 916us/step - loss: 67.0899\n",
            "Epoch 16/300\n",
            "16/16 [==============================] - 0s 948us/step - loss: 65.2219\n",
            "Epoch 17/300\n",
            "16/16 [==============================] - 0s 282us/step - loss: 66.5747\n",
            "Epoch 18/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 60.4770\n",
            "Epoch 19/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 48.1934\n",
            "Epoch 20/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 65.9274\n",
            "Epoch 21/300\n",
            "16/16 [==============================] - 0s 939us/step - loss: 62.7642\n",
            "Epoch 22/300\n",
            "16/16 [==============================] - 0s 880us/step - loss: 49.8924\n",
            "Epoch 23/300\n",
            "16/16 [==============================] - 0s 535us/step - loss: 69.8639\n",
            "Epoch 24/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 53.8035\n",
            "Epoch 25/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 59.3025\n",
            "Epoch 26/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 55.1749\n",
            "Epoch 27/300\n",
            "16/16 [==============================] - 0s 799us/step - loss: 49.2127\n",
            "Epoch 28/300\n",
            "16/16 [==============================] - 0s 653us/step - loss: 45.8149\n",
            "Epoch 29/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 68.9916\n",
            "Epoch 30/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 39.4446\n",
            "Epoch 31/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 63.2192\n",
            "Epoch 32/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 57.2387\n",
            "Epoch 33/300\n",
            "16/16 [==============================] - 0s 372us/step - loss: 59.1101\n",
            "Epoch 34/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 53.3121\n",
            "Epoch 35/300\n",
            "16/16 [==============================] - 0s 507us/step - loss: 47.8794\n",
            "Epoch 36/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 57.1110\n",
            "Epoch 37/300\n",
            "16/16 [==============================] - 0s 993us/step - loss: 54.5614\n",
            "Epoch 38/300\n",
            "16/16 [==============================] - 0s 721us/step - loss: 51.4925\n",
            "Epoch 39/300\n",
            "16/16 [==============================] - 0s 989us/step - loss: 53.8718\n",
            "Epoch 40/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 42.9694\n",
            "Epoch 41/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 57.0659\n",
            "Epoch 42/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 46.5896\n",
            "Epoch 43/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 54.1819\n",
            "Epoch 44/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 55.6883\n",
            "Epoch 45/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 50.3252\n",
            "Epoch 46/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 44.5029\n",
            "Epoch 47/300\n",
            "16/16 [==============================] - 0s 972us/step - loss: 56.0963\n",
            "Epoch 48/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 48.7772\n",
            "Epoch 49/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 44.2530\n",
            "Epoch 50/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 49.4450\n",
            "Epoch 51/300\n",
            "16/16 [==============================] - 0s 921us/step - loss: 51.1298\n",
            "Epoch 52/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 49.5782\n",
            "Epoch 53/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 46.5402\n",
            "Epoch 54/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 54.2680\n",
            "Epoch 55/300\n",
            "16/16 [==============================] - 0s 974us/step - loss: 44.8259\n",
            "Epoch 56/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 54.0502\n",
            "Epoch 57/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 45.5676\n",
            "Epoch 58/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 44.2134\n",
            "Epoch 59/300\n",
            "16/16 [==============================] - 0s 952us/step - loss: 50.3029\n",
            "Epoch 60/300\n",
            "16/16 [==============================] - 0s 778us/step - loss: 40.3519\n",
            "Epoch 61/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 52.0221\n",
            "Epoch 62/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 52.3811\n",
            "Epoch 63/300\n",
            "16/16 [==============================] - 0s 956us/step - loss: 44.1439\n",
            "Epoch 64/300\n",
            "16/16 [==============================] - 0s 593us/step - loss: 45.4819\n",
            "Epoch 65/300\n",
            "16/16 [==============================] - 0s 660us/step - loss: 47.9796\n",
            "Epoch 66/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 39.3884\n",
            "Epoch 67/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 43.7453\n",
            "Epoch 68/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 52.1148\n",
            "Epoch 69/300\n",
            "16/16 [==============================] - 0s 681us/step - loss: 51.1082\n",
            "Epoch 70/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 45.0260\n",
            "Epoch 71/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 43.5658\n",
            "Epoch 72/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 46.9931\n",
            "Epoch 73/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 39.2798\n",
            "Epoch 74/300\n",
            "16/16 [==============================] - 0s 736us/step - loss: 53.7824\n",
            "Epoch 75/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 30.4879\n",
            "Epoch 76/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 54.1828\n",
            "Epoch 77/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 42.1218\n",
            "Epoch 78/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 41.8376\n",
            "Epoch 79/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 47.8388\n",
            "Epoch 80/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 48.1345\n",
            "Epoch 81/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 43.6313\n",
            "Epoch 82/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 47.7768\n",
            "Epoch 83/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 41.0724\n",
            "Epoch 84/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 44.9118\n",
            "Epoch 85/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 41.6187\n",
            "Epoch 86/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 45.1328\n",
            "Epoch 87/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 47.0672\n",
            "Epoch 88/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 46.9444\n",
            "Epoch 89/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 49.7738\n",
            "Epoch 90/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.8705\n",
            "Epoch 91/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 47.0170\n",
            "Epoch 92/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 41.5996\n",
            "Epoch 93/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.2165\n",
            "Epoch 94/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 46.8677\n",
            "Epoch 95/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 41.6361\n",
            "Epoch 96/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 50.4483\n",
            "Epoch 97/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 46.1431\n",
            "Epoch 98/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 42.7197\n",
            "Epoch 99/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 39.5940\n",
            "Epoch 100/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 47.3102\n",
            "Epoch 101/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.1327\n",
            "Epoch 102/300\n",
            "16/16 [==============================] - 0s 844us/step - loss: 47.2407\n",
            "Epoch 103/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 43.3887\n",
            "Epoch 104/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 39.8315\n",
            "Epoch 105/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 50.0990\n",
            "Epoch 106/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 40.0417\n",
            "Epoch 107/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 43.8668\n",
            "Epoch 108/300\n",
            "16/16 [==============================] - 0s 555us/step - loss: 44.3885\n",
            "Epoch 109/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 39.3460\n",
            "Epoch 110/300\n",
            "16/16 [==============================] - 0s 946us/step - loss: 40.5165\n",
            "Epoch 111/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 38.6774\n",
            "Epoch 112/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 48.0236\n",
            "Epoch 113/300\n",
            "16/16 [==============================] - 0s 971us/step - loss: 40.7064\n",
            "Epoch 114/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 44.0855\n",
            "Epoch 115/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 38.0874\n",
            "Epoch 116/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 48.3556\n",
            "Epoch 117/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 42.0789\n",
            "Epoch 118/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 39.4649\n",
            "Epoch 119/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 46.1261\n",
            "Epoch 120/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 43.0226\n",
            "Epoch 121/300\n",
            "16/16 [==============================] - 0s 445us/step - loss: 43.3200\n",
            "Epoch 122/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 31.5728\n",
            "Epoch 123/300\n",
            "16/16 [==============================] - 0s 607us/step - loss: 42.3444\n",
            "Epoch 124/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 40.2229\n",
            "Epoch 125/300\n",
            "16/16 [==============================] - 0s 870us/step - loss: 46.3186\n",
            "Epoch 126/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.2320\n",
            "Epoch 127/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 42.2656\n",
            "Epoch 128/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 39.5055\n",
            "Epoch 129/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 37.8156\n",
            "Epoch 130/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 40.5245\n",
            "Epoch 131/300\n",
            "16/16 [==============================] - 0s 959us/step - loss: 41.2048\n",
            "Epoch 132/300\n",
            "16/16 [==============================] - 0s 908us/step - loss: 40.6049\n",
            "Epoch 133/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 39.0518\n",
            "Epoch 134/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.8677\n",
            "Epoch 135/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 40.7800\n",
            "Epoch 136/300\n",
            "16/16 [==============================] - 0s 793us/step - loss: 42.0835\n",
            "Epoch 137/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 37.4267\n",
            "Epoch 138/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 42.8029\n",
            "Epoch 139/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 30.8403\n",
            "Epoch 140/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 38.7061\n",
            "Epoch 141/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 35.5082\n",
            "Epoch 142/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.4644\n",
            "Epoch 143/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 40.9387\n",
            "Epoch 144/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 37.5562\n",
            "Epoch 145/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 38.1920\n",
            "Epoch 146/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 38.1592\n",
            "Epoch 147/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 40.3076\n",
            "Epoch 148/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.9697\n",
            "Epoch 149/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 40.1808\n",
            "Epoch 150/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.3352\n",
            "Epoch 151/300\n",
            "16/16 [==============================] - 0s 933us/step - loss: 34.5794\n",
            "Epoch 152/300\n",
            "16/16 [==============================] - 0s 373us/step - loss: 39.5216\n",
            "Epoch 153/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.5475\n",
            "Epoch 154/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 40.7646\n",
            "Epoch 155/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 38.6320\n",
            "Epoch 156/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.0569\n",
            "Epoch 157/300\n",
            "16/16 [==============================] - 0s 920us/step - loss: 37.8838\n",
            "Epoch 158/300\n",
            "16/16 [==============================] - 0s 272us/step - loss: 38.6166\n",
            "Epoch 159/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 37.9737\n",
            "Epoch 160/300\n",
            "16/16 [==============================] - 0s 334us/step - loss: 43.0292\n",
            "Epoch 161/300\n",
            "16/16 [==============================] - 0s 1000us/step - loss: 33.0002\n",
            "Epoch 162/300\n",
            "16/16 [==============================] - 0s 1000us/step - loss: 39.8340\n",
            "Epoch 163/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 34.9699\n",
            "Epoch 164/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 33.4230\n",
            "Epoch 165/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 37.9509\n",
            "Epoch 166/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 35.3259\n",
            "Epoch 167/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 33.2784\n",
            "Epoch 168/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.2083\n",
            "Epoch 169/300\n",
            "16/16 [==============================] - 0s 959us/step - loss: 35.6595\n",
            "Epoch 170/300\n",
            "16/16 [==============================] - 0s 521us/step - loss: 38.3887\n",
            "Epoch 171/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.5311\n",
            "Epoch 172/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 36.5025\n",
            "Epoch 173/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.7895\n",
            "Epoch 174/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 38.3310\n",
            "Epoch 175/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.5446\n",
            "Epoch 176/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 32.8783\n",
            "Epoch 177/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 36.8321\n",
            "Epoch 178/300\n",
            "16/16 [==============================] - 0s 976us/step - loss: 31.2518\n",
            "Epoch 179/300\n",
            "16/16 [==============================] - 0s 603us/step - loss: 39.1247\n",
            "Epoch 180/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 40.4819\n",
            "Epoch 181/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 28.0796\n",
            "Epoch 182/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 38.3757\n",
            "Epoch 183/300\n",
            "16/16 [==============================] - 0s 867us/step - loss: 37.5898\n",
            "Epoch 184/300\n",
            "16/16 [==============================] - 0s 14us/step - loss: 36.0303\n",
            "Epoch 185/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 29.8032\n",
            "Epoch 186/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 39.4724\n",
            "Epoch 187/300\n",
            "16/16 [==============================] - 0s 979us/step - loss: 33.7209\n",
            "Epoch 188/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 35.5591\n",
            "Epoch 189/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 33.2769\n",
            "Epoch 190/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 33.1337\n",
            "Epoch 191/300\n",
            "16/16 [==============================] - 0s 930us/step - loss: 33.6224\n",
            "Epoch 192/300\n",
            "16/16 [==============================] - 0s 82us/step - loss: 35.6494\n",
            "Epoch 193/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 31.0181\n",
            "Epoch 194/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 38.8214\n",
            "Epoch 195/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 38.3639\n",
            "Epoch 196/300\n",
            "16/16 [==============================] - 0s 926us/step - loss: 32.9071\n",
            "Epoch 197/300\n",
            "16/16 [==============================] - 0s 540us/step - loss: 31.6995\n",
            "Epoch 198/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.4380\n",
            "Epoch 199/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 35.3404\n",
            "Epoch 200/300\n",
            "16/16 [==============================] - 0s 981us/step - loss: 33.4726\n",
            "Epoch 201/300\n",
            "16/16 [==============================] - 0s 163us/step - loss: 35.5913\n",
            "Epoch 202/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 29.7799\n",
            "Epoch 203/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.5697\n",
            "Epoch 204/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 33.1950\n",
            "Epoch 205/300\n",
            "16/16 [==============================] - 0s 710us/step - loss: 35.7126\n",
            "Epoch 206/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 33.3541\n",
            "Epoch 207/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 26.5665\n",
            "Epoch 208/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.9644\n",
            "Epoch 209/300\n",
            "16/16 [==============================] - 0s 211us/step - loss: 32.2842\n",
            "Epoch 210/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 38.0670\n",
            "Epoch 211/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 32.5825\n",
            "Epoch 212/300\n",
            "16/16 [==============================] - 0s 876us/step - loss: 34.1243\n",
            "Epoch 213/300\n",
            "16/16 [==============================] - 0s 914us/step - loss: 35.6394\n",
            "Epoch 214/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 28.9194\n",
            "Epoch 215/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 35.2836\n",
            "Epoch 216/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 31.1833\n",
            "Epoch 217/300\n",
            "16/16 [==============================] - 0s 869us/step - loss: 33.1771\n",
            "Epoch 218/300\n",
            "16/16 [==============================] - 0s 755us/step - loss: 26.6059\n",
            "Epoch 219/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.8532\n",
            "Epoch 220/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 34.4847\n",
            "Epoch 221/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 39.8582\n",
            "Epoch 222/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.2117\n",
            "Epoch 223/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 29.2122\n",
            "Epoch 224/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 33.8160\n",
            "Epoch 225/300\n",
            "16/16 [==============================] - 0s 914us/step - loss: 34.1230\n",
            "Epoch 226/300\n",
            "16/16 [==============================] - 0s 81us/step - loss: 28.6994\n",
            "Epoch 227/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 33.8004\n",
            "Epoch 228/300\n",
            "16/16 [==============================] - 0s 345us/step - loss: 33.6338\n",
            "Epoch 229/300\n",
            "16/16 [==============================] - 0s 3ms/step - loss: 30.5547\n",
            "Epoch 230/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 29.8101\n",
            "Epoch 231/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 31.4871\n",
            "Epoch 232/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 24.3452\n",
            "Epoch 233/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 38.0081\n",
            "Epoch 234/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 32.4308\n",
            "Epoch 235/300\n",
            "16/16 [==============================] - 0s 953us/step - loss: 24.4009\n",
            "Epoch 236/300\n",
            "16/16 [==============================] - 0s 610us/step - loss: 35.0210\n",
            "Epoch 237/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 30.0807\n",
            "Epoch 238/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 28.9462\n",
            "Epoch 239/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 35.3978\n",
            "Epoch 240/300\n",
            "16/16 [==============================] - 0s 971us/step - loss: 26.2184\n",
            "Epoch 241/300\n",
            "16/16 [==============================] - 0s 849us/step - loss: 25.5034\n",
            "Epoch 242/300\n",
            "16/16 [==============================] - 0s 401us/step - loss: 32.1863\n",
            "Epoch 243/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 29.1277\n",
            "Epoch 244/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 28.9823\n",
            "Epoch 245/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 35.9212\n",
            "Epoch 246/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 29.8965\n",
            "Epoch 247/300\n",
            "16/16 [==============================] - 0s 969us/step - loss: 30.3535\n",
            "Epoch 248/300\n",
            "16/16 [==============================] - 0s 475us/step - loss: 28.1849\n",
            "Epoch 249/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 29.3684\n",
            "Epoch 250/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 29.4060\n",
            "Epoch 251/300\n",
            "16/16 [==============================] - 0s 909us/step - loss: 29.5247\n",
            "Epoch 252/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.1872\n",
            "Epoch 253/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 29.5840\n",
            "Epoch 254/300\n",
            "16/16 [==============================] - 0s 556us/step - loss: 28.5094\n",
            "Epoch 255/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 29.5101\n",
            "Epoch 256/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 31.5575\n",
            "Epoch 257/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.1234\n",
            "Epoch 258/300\n",
            "16/16 [==============================] - 0s 980us/step - loss: 28.3397\n",
            "Epoch 259/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 26.6952\n",
            "Epoch 260/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.5756\n",
            "Epoch 261/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.2402\n",
            "Epoch 262/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 28.4589\n",
            "Epoch 263/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 23.3643\n",
            "Epoch 264/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 29.2985\n",
            "Epoch 265/300\n",
            "16/16 [==============================] - 0s 675us/step - loss: 28.4374\n",
            "Epoch 266/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 22.4370\n",
            "Epoch 267/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 31.1126\n",
            "Epoch 268/300\n",
            "16/16 [==============================] - 0s 504us/step - loss: 27.7612\n",
            "Epoch 269/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 22.7370\n",
            "Epoch 270/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 29.0493\n",
            "Epoch 271/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 28.0168\n",
            "Epoch 272/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 27.4685\n",
            "Epoch 273/300\n",
            "16/16 [==============================] - 0s 980us/step - loss: 28.0822\n",
            "Epoch 274/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 26.1431\n",
            "Epoch 275/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 30.2907\n",
            "Epoch 276/300\n",
            "16/16 [==============================] - 0s 993us/step - loss: 28.7578\n",
            "Epoch 277/300\n",
            "16/16 [==============================] - 0s 341us/step - loss: 23.6150\n",
            "Epoch 278/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 25.9272\n",
            "Epoch 279/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 26.7011\n",
            "Epoch 280/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 30.3455\n",
            "Epoch 281/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 25.9725\n",
            "Epoch 282/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 25.1100\n",
            "Epoch 283/300\n",
            "16/16 [==============================] - 0s 964us/step - loss: 26.0300\n",
            "Epoch 284/300\n",
            "16/16 [==============================] - 0s 410us/step - loss: 28.3060\n",
            "Epoch 285/300\n",
            "16/16 [==============================] - 0s 373us/step - loss: 27.1737\n",
            "Epoch 286/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 22.2936\n",
            "Epoch 287/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 26.4792\n",
            "Epoch 288/300\n",
            "16/16 [==============================] - 0s 998us/step - loss: 26.5700\n",
            "Epoch 289/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 26.1301\n",
            "Epoch 290/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.2121\n",
            "Epoch 291/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 23.2536\n",
            "Epoch 292/300\n",
            "16/16 [==============================] - 0s 933us/step - loss: 26.7757\n",
            "Epoch 293/300\n",
            "16/16 [==============================] - 0s 677us/step - loss: 19.5855\n",
            "Epoch 294/300\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 25.5185\n",
            "Epoch 295/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 27.2390\n",
            "Epoch 296/300\n",
            "16/16 [==============================] - 0s 803us/step - loss: 28.3751\n",
            "Epoch 297/300\n",
            "16/16 [==============================] - 0s 0s/step - loss: 24.6947\n",
            "Epoch 298/300\n",
            "16/16 [==============================] - 0s 999us/step - loss: 29.0628\n",
            "Epoch 299/300\n",
            "16/16 [==============================] - 0s 280us/step - loss: 25.3080\n",
            "Epoch 300/300\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 26.4482\n",
            "Epoch 1/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 25.8320\n",
            "Epoch 2/10\n",
            "16/16 [==============================] - 0s 934us/step - loss: 24.9897\n",
            "Epoch 3/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 21.7864\n",
            "Epoch 4/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 29.4049\n",
            "Epoch 5/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 23.5112\n",
            "Epoch 6/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 23.4567\n",
            "Epoch 7/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 24.1371\n",
            "Epoch 8/10\n",
            "16/16 [==============================] - 0s 2ms/step - loss: 24.8627\n",
            "Epoch 9/10\n",
            "16/16 [==============================] - 0s 779us/step - loss: 23.0323\n",
            "Epoch 10/10\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 26.8924\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1ce795dd850>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=300)\n",
        "model.fit(x_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lUrCUJmtUwDu"
      },
      "outputs": [],
      "source": [
        "# 모델 이용\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSvZMqB4u_Co"
      },
      "source": [
        "# 텐서플로우 CNN - 이미지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M-SDI-l4XI8"
      },
      "source": [
        "## 차원수 - 포함관계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6vco38YBUw64"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3,)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "d1 = np.array([1, 2, 3])\n",
        "d1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0bHutcv84mVo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5, 3)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d2 = np.array([d1, d1, d1, d1, d1])\n",
        "d2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "k64CyEEN4tqf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4, 5, 3)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d3 = np.array([d2, d2, d2, d2])\n",
        "d3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "xX6j0SLM41m2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2, 4, 5, 3)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d4 = np.array([d3, d3])\n",
        "d4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH4UgVgR7Iv7"
      },
      "source": [
        "## 이미지 데이터 구경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bJNG0ZLE473s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "DY2TcInS7Qy2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1ce7d5dd890>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAabUlEQVR4nO3dfWxT5/n/8Y/LgxuQ4ymCxM4IUdSCtjaMiofyIMqTREa0okE2ibbTBJuEaAlIKGVojEmw/UEQFajqWOmK9mXQwUCqKEOCFYIgoYxRUUoLox0KI4x0kKVkYIcUzCj37w+EfzUJKcfYXLHzfklHwueci3Nx91Y+vePjY59zzgkAAAOPWDcAAOi+CCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCY6WndwN1u3bqlCxcuKBAIyOfzWbcDAPDIOafW1lYVFhbqkUc6X+t0uRC6cOGCioqKrNsAADygxsZGDRgwoNNzutyv4wKBgHULAIAUuJ+f52kLoddff10lJSV69NFHNXz4cL333nv3Vcev4AAgO9zPz/O0hNC2bdu0cOFCLV26VMePH9czzzyj8vJynT9/Ph2XAwBkKF86nqI9atQoDRs2TOvWrYvv+/a3v63p06erurq609poNKpgMJjqlgAAD1kkElFubm6n56R8JXTjxg0dO3ZMZWVlCfvLysp0+PDhdufHYjFFo9GEDQDQPaQ8hC5duqQvv/xSBQUFCfsLCgrU1NTU7vzq6moFg8H4xp1xANB9pO3GhLvfkHLOdfgm1ZIlSxSJROJbY2NjuloCAHQxKf+cUL9+/dSjR492q57m5uZ2qyNJ8vv98vv9qW4DAJABUr4S6t27t4YPH66ampqE/TU1NRo7dmyqLwcAyGBpeWJCVVWVfvzjH2vEiBEaM2aM3nzzTZ0/f14vvvhiOi4HAMhQaQmhmTNnqqWlRb/+9a918eJFlZaWavfu3SouLk7H5QAAGSotnxN6EHxOCACyg8nnhAAAuF+EEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwk/IQWr58uXw+X8IWCoVSfRkAQBbomY6/9Mknn9S+ffvir3v06JGOywAAMlxaQqhnz56sfgAAXyst7wnV19ersLBQJSUleu6553T27Nl7nhuLxRSNRhM2AED3kPIQGjVqlDZt2qQ9e/Zo/fr1ampq0tixY9XS0tLh+dXV1QoGg/GtqKgo1S0BALoon3POpfMCbW1teuyxx7R48WJVVVW1Ox6LxRSLxeKvo9EoQQQAWSASiSg3N7fTc9LyntBX9e3bV0OGDFF9fX2Hx/1+v/x+f7rbAAB0QWn/nFAsFtOnn36qcDic7ksBADJMykNo0aJFqqurU0NDg95//3398Ic/VDQa1axZs1J9KQBAhkv5r+M+++wzPf/887p06ZL69++v0aNH68iRIyouLk71pQAAGS7tNyZ4FY1GFQwGrdsA7tuAAQM813z22Wdp6AT30rdv36TqXnvtNc81P/rRjzzXPP30055rTpw44bnmYbufGxN4dhwAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzaf9SOyCTFBYWeq45c+aM55pPPvnEc82wYcM812SjZ5991nPN+vXrk7pWfn6+55otW7Z4rmlpafFcky1YCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzPAUbWSlnJycpOpee+01zzW9evXyXDNo0CDPNdloxIgRnmveeustzzW5ubmeayTp//7v/zzXvPTSS55rbt686bkmW7ASAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYHmCIrfe9730uqbsaMGZ5rknn45KJFizzXdHWBQMBzzdtvv+25JpmHke7bt89zjSRVVlZ6runODyNNBishAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZniAKbq8wYMHe65ZuXJlGjrp2F//+lfPNb/73e/S0ImtV155xXNNUVGR55rr1697rknmQaSSdOPGjaTqcP9YCQEAzBBCAAAznkPo4MGDmjZtmgoLC+Xz+bRjx46E4845LV++XIWFhcrJydHEiRN16tSpVPULAMginkOora1NQ4cO1dq1azs8vmrVKq1Zs0Zr167V0aNHFQqFNGXKFLW2tj5wswCA7OL5xoTy8nKVl5d3eMw5p1dffVVLly5VRUWFJGnjxo0qKCjQli1bNHfu3AfrFgCQVVL6nlBDQ4OamppUVlYW3+f3+zVhwgQdPny4w5pYLKZoNJqwAQC6h5SGUFNTkySpoKAgYX9BQUH82N2qq6sVDAbjWzK3bAIAMlNa7o7z+XwJr51z7fbdsWTJEkUikfjW2NiYjpYAAF1QSj+sGgqFJN1eEYXD4fj+5ubmdqujO/x+v/x+fyrbAABkiJSuhEpKShQKhVRTUxPfd+PGDdXV1Wns2LGpvBQAIAt4XgldvXpVZ86cib9uaGjQRx99pLy8PA0cOFALFy7UihUrNGjQIA0aNEgrVqxQnz599MILL6S0cQBA5vMcQh988IEmTZoUf11VVSVJmjVrlv7whz9o8eLFunbtmubNm6fLly9r1KhR2rt3rwKBQOq6BgBkBZ9zzlk38VXRaFTBYNC6DaTJ6NGjPdfc/VSO+9G/f3/PNZKS+lD1hAkTPNd8/PHHnmsepqFDh3quOXTokOeaPn36eK756U9/6rlm48aNnmvw4CKRiHJzczs9h2fHAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMpPSbVdG9JPNFhW+//bbnmmSeiH3lyhXPNdL//2oSL5J5Inbfvn0913zjG9/wXDNmzBjPNZL0m9/8xnNNMk/ETkZeXt5DuQ4eDlZCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzPicc866ia+KRqMKBoPWbXQrjz/+eFJ1e/fu9VxTXFyc1LW8+vzzz5Oq27p1q+eap556ynNNQUGB55rBgwd7rvH5fJ5rJKmL/VhI8OGHH3quGTlyZBo6wdeJRCLKzc3t9BxWQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMz0tG4A9pYsWZJU3cN6GGky+vfvn1TdggULUtxJ9/Hvf//bc00yD4x94403PNeg62IlBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwPMIUaGxutW0AWmDt3rueav/zlL2noBJmElRAAwAwhBAAw4zmEDh48qGnTpqmwsFA+n087duxIOD579mz5fL6EbfTo0anqFwCQRTyHUFtbm4YOHaq1a9fe85ypU6fq4sWL8W337t0P1CQAIDt5vjGhvLxc5eXlnZ7j9/sVCoWSbgoA0D2k5T2h2tpa5efna/DgwZozZ46am5vveW4sFlM0Gk3YAADdQ8pDqLy8XJs3b9b+/fu1evVqHT16VJMnT1YsFuvw/OrqagWDwfhWVFSU6pYAAF1Uyj8nNHPmzPifS0tLNWLECBUXF2vXrl2qqKhod/6SJUtUVVUVfx2NRgkiAOgm0v5h1XA4rOLiYtXX13d43O/3y+/3p7sNAEAXlPbPCbW0tKixsVHhcDjdlwIAZBjPK6GrV6/qzJkz8dcNDQ366KOPlJeXp7y8PC1fvlw/+MEPFA6Hde7cOf3iF79Qv379NGPGjJQ2DgDIfJ5D6IMPPtCkSZPir++8nzNr1iytW7dOJ0+e1KZNm3TlyhWFw2FNmjRJ27ZtUyAQSF3XAICs4HPOOesmvioajSoYDFq3gftQXFzsuebq1auea6ZMmeK5Jlnnz5/3XPPEE094rnnzzTc91yTD5/MlVfef//zHc83jjz/uuSaZ+YDMEYlElJub2+k5PDsOAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGp2gDDygvL89zzeeff56GTtpL9ina3/nOdzzX/P3vf0/qWshePEUbANClEUIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMNPTugGgK/H7/Z5rfvazn6Whk9TYt29fUnX/+Mc/UtwJ0DFWQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMz4nHPOuomvikajCgaD1m2gmyotLfVc8/HHH6ehk/b++9//eq4ZOHBgUte6du1aUnXAV0UiEeXm5nZ6DishAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZnpaNwCkg9/vT6rul7/8ZYo76dj//vc/zzXf/e53PdfwIFJ0dayEAABmCCEAgBlPIVRdXa2RI0cqEAgoPz9f06dP1+nTpxPOcc5p+fLlKiwsVE5OjiZOnKhTp06ltGkAQHbwFEJ1dXWqrKzUkSNHVFNTo5s3b6qsrExtbW3xc1atWqU1a9Zo7dq1Onr0qEKhkKZMmaLW1taUNw8AyGyebkx49913E15v2LBB+fn5OnbsmMaPHy/nnF599VUtXbpUFRUVkqSNGzeqoKBAW7Zs0dy5c1PXOQAg4z3Qe0KRSESSlJeXJ0lqaGhQU1OTysrK4uf4/X5NmDBBhw8f7vDviMViikajCRsAoHtIOoScc6qqqtK4ceNUWloqSWpqapIkFRQUJJxbUFAQP3a36upqBYPB+FZUVJRsSwCADJN0CM2fP18nTpzQn/70p3bHfD5fwmvnXLt9dyxZskSRSCS+NTY2JtsSACDDJPVh1QULFmjnzp06ePCgBgwYEN8fCoUk3V4RhcPh+P7m5uZ2q6M7/H5/0h8sBABkNk8rIeec5s+fr+3bt2v//v0qKSlJOF5SUqJQKKSampr4vhs3bqiurk5jx45NTccAgKzhaSVUWVmpLVu26M9//rMCgUD8fZ5gMKicnBz5fD4tXLhQK1as0KBBgzRo0CCtWLFCffr00QsvvJCWfwAAIHN5CqF169ZJkiZOnJiwf8OGDZo9e7YkafHixbp27ZrmzZuny5cva9SoUdq7d68CgUBKGgYAZA+fc85ZN/FV0WhUwWDQug1kuKeeeiqpumPHjqW2kXvYtGmT55qf/OQnaegESJ9IJKLc3NxOz+HZcQAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM0l9syrwMPXr189zzVtvvZWGTjp2/fp1zzUrV65MQydA5mElBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwPMMVD1bOn9yn3q1/9ynPNE0884blGkm7duuW55pVXXvFcc/r0ac81QDZiJQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMCMzznnrJv4qmg0qmAwaN0G0mTEiBGea95///00dNKxQ4cOea6ZMGFCGjoBMl8kElFubm6n57ASAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYKandQPoXi5fvuy55urVq55rotGo5xpJmjdvXlJ1AJLDSggAYIYQAgCY8RRC1dXVGjlypAKBgPLz8zV9+nSdPn064ZzZs2fL5/MlbKNHj05p0wCA7OAphOrq6lRZWakjR46opqZGN2/eVFlZmdra2hLOmzp1qi5evBjfdu/endKmAQDZwdONCe+++27C6w0bNig/P1/Hjh3T+PHj4/v9fr9CoVBqOgQAZK0Hek8oEolIkvLy8hL219bWKj8/X4MHD9acOXPU3Nx8z78jFospGo0mbACA7iHpEHLOqaqqSuPGjVNpaWl8f3l5uTZv3qz9+/dr9erVOnr0qCZPnqxYLNbh31NdXa1gMBjfioqKkm0JAJBhfM45l0xhZWWldu3apUOHDmnAgAH3PO/ixYsqLi7W1q1bVVFR0e54LBZLCKhoNEoQZbHHHnvMc82HH37ouSbZFfXUqVM915w6dSqpawHZLhKJKDc3t9Nzkvqw6oIFC7Rz504dPHiw0wCSpHA4rOLiYtXX13d43O/3y+/3J9MGACDDeQoh55wWLFigd955R7W1tSopKfnampaWFjU2NiocDifdJAAgO3l6T6iyslJ//OMftWXLFgUCATU1NampqUnXrl2TdPvxKosWLdLf/vY3nTt3TrW1tZo2bZr69eunGTNmpOUfAADIXJ5WQuvWrZMkTZw4MWH/hg0bNHv2bPXo0UMnT57Upk2bdOXKFYXDYU2aNEnbtm1TIBBIWdMAgOzg+ddxncnJydGePXseqCEAQPfBU7TxUP3zn//0XBMMBtPQCYCugAeYAgDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMNPlQsg5Z90CACAF7ufneZcLodbWVusWAAApcD8/z32uiy09bt26pQsXLigQCMjn8yUci0ajKioqUmNjo3Jzc406tMc43MY43MY43MY43NYVxsE5p9bWVhUWFuqRRzpf6/R8SD3dt0ceeUQDBgzo9Jzc3NxuPcnuYBxuYxxuYxxuYxxusx6HYDB4X+d1uV/HAQC6D0IIAGAmo0LI7/dr2bJl8vv91q2YYhxuYxxuYxxuYxxuy7Rx6HI3JgAAuo+MWgkBALILIQQAMEMIAQDMEEIAADMZFUKvv/66SkpK9Oijj2r48OF67733rFt6qJYvXy6fz5ewhUIh67bS7uDBg5o2bZoKCwvl8/m0Y8eOhOPOOS1fvlyFhYXKycnRxIkTderUKZtm0+jrxmH27Nnt5sfo0aNtmk2T6upqjRw5UoFAQPn5+Zo+fbpOnz6dcE53mA/3Mw6ZMh8yJoS2bdumhQsXaunSpTp+/LieeeYZlZeX6/z589atPVRPPvmkLl68GN9Onjxp3VLatbW1aejQoVq7dm2Hx1etWqU1a9Zo7dq1Onr0qEKhkKZMmZJ1zyH8unGQpKlTpybMj927dz/EDtOvrq5OlZWVOnLkiGpqanTz5k2VlZWpra0tfk53mA/3Mw5ShswHlyGefvpp9+KLLybs+9a3vuV+/vOfG3X08C1btswNHTrUug1Tktw777wTf33r1i0XCoXcypUr4/uuX7/ugsGge+ONNww6fDjuHgfnnJs1a5b7/ve/b9KPlebmZifJ1dXVOee673y4exycy5z5kBEroRs3bujYsWMqKytL2F9WVqbDhw8bdWWjvr5ehYWFKikp0XPPPaezZ89at2SqoaFBTU1NCXPD7/drwoQJ3W5uSFJtba3y8/M1ePBgzZkzR83NzdYtpVUkEpEk5eXlSeq+8+HucbgjE+ZDRoTQpUuX9OWXX6qgoCBhf0FBgZqamoy6evhGjRqlTZs2ac+ePVq/fr2ampo0duxYtbS0WLdm5s5//+4+NySpvLxcmzdv1v79+7V69WodPXpUkydPViwWs24tLZxzqqqq0rhx41RaWiqpe86HjsZBypz50OWeot2Zu7/awTnXbl82Ky8vj/95yJAhGjNmjB577DFt3LhRVVVVhp3Z6+5zQ5JmzpwZ/3NpaalGjBih4uJi7dq1SxUVFYadpcf8+fN14sQJHTp0qN2x7jQf7jUOmTIfMmIl1K9fP/Xo0aPd/8k0Nze3+z+e7qRv374aMmSI6uvrrVsxc+fuQOZGe+FwWMXFxVk5PxYsWKCdO3fqwIEDCV/90t3mw73GoSNddT5kRAj17t1bw4cPV01NTcL+mpoajR071qgre7FYTJ9++qnC4bB1K2ZKSkoUCoUS5saNGzdUV1fXreeGJLW0tKixsTGr5odzTvPnz9f27du1f/9+lZSUJBzvLvPh68ahI112PhjeFOHJ1q1bXa9evdzvf/9798knn7iFCxe6vn37unPnzlm39tC8/PLLrra21p09e9YdOXLEPfvssy4QCGT9GLS2trrjx4+748ePO0luzZo17vjx4+5f//qXc865lStXumAw6LZv3+5Onjzpnn/+eRcOh100GjXuPLU6G4fW1lb38ssvu8OHD7uGhgZ34MABN2bMGPfNb34zq8bhpZdecsFg0NXW1rqLFy/Gty+++CJ+TneYD183Dpk0HzImhJxz7re//a0rLi52vXv3dsOGDUu4HbE7mDlzpguHw65Xr16usLDQVVRUuFOnTlm3lXYHDhxwktpts2bNcs7dvi132bJlLhQKOb/f78aPH+9Onjxp23QadDYOX3zxhSsrK3P9+/d3vXr1cgMHDnSzZs1y58+ft247pTr690tyGzZsiJ/THebD141DJs0HvsoBAGAmI94TAgBkJ0IIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGb+HwNT8svmqZIBAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "i = 2451\n",
        "print(y_train[i])\n",
        "plt.imshow(x_train[i], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "F0YhaTo172ko"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>157</td>\n",
              "      <td>248</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>248</td>\n",
              "      <td>206</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>76</td>\n",
              "      <td>231</td>\n",
              "      <td>253</td>\n",
              "      <td>163</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>172</td>\n",
              "      <td>253</td>\n",
              "      <td>244</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>239</td>\n",
              "      <td>253</td>\n",
              "      <td>155</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>84</td>\n",
              "      <td>253</td>\n",
              "      <td>249</td>\n",
              "      <td>103</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>224</td>\n",
              "      <td>253</td>\n",
              "      <td>185</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>38</td>\n",
              "      <td>220</td>\n",
              "      <td>253</td>\n",
              "      <td>190</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>253</td>\n",
              "      <td>245</td>\n",
              "      <td>36</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>232</td>\n",
              "      <td>253</td>\n",
              "      <td>240</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>244</td>\n",
              "      <td>253</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>58</td>\n",
              "      <td>230</td>\n",
              "      <td>253</td>\n",
              "      <td>237</td>\n",
              "      <td>95</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>27</td>\n",
              "      <td>84</td>\n",
              "      <td>231</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>114</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>222</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>232</td>\n",
              "      <td>144</td>\n",
              "      <td>192</td>\n",
              "      <td>215</td>\n",
              "      <td>253</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>157</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>226</td>\n",
              "      <td>138</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>128</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>254</td>\n",
              "      <td>253</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>19</td>\n",
              "      <td>88</td>\n",
              "      <td>88</td>\n",
              "      <td>58</td>\n",
              "      <td>100</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>255</td>\n",
              "      <td>232</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>254</td>\n",
              "      <td>44</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>135</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>186</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>45</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>235</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>168</td>\n",
              "      <td>253</td>\n",
              "      <td>248</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>159</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>211</td>\n",
              "      <td>253</td>\n",
              "      <td>245</td>\n",
              "      <td>39</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>149</td>\n",
              "      <td>253</td>\n",
              "      <td>251</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>253</td>\n",
              "      <td>253</td>\n",
              "      <td>193</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>241</td>\n",
              "      <td>228</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3   4   5   6    7    8    9    10   11   12   13   14   15  \\\n",
              "0    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
              "1    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
              "2    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
              "3    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
              "4    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
              "5    0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
              "6    0   0   0   0   0   0   0    0    0    0    0    0    0   28    0    0   \n",
              "7    0   0   0   0   0   0   0    0    0    0    0    0   26  248  206    0   \n",
              "8    0   0   0   0   0   0   0    0    0    0    0    9  172  253  244    0   \n",
              "9    0   0   0   0   0   0   0    0    0    0    0   84  253  249  103    0   \n",
              "10   0   0   0   0   0   0   0    0    0    0   38  220  253  190    0    0   \n",
              "11   0   0   0   0   0   0   0    0    0   56  232  253  240   47    0    0   \n",
              "12   0   0   0   0   0   0   0    0   58  230  253  237   95    0   11   27   \n",
              "13   0   0   0   0   0   0   0   36  222  253  253  232  144  192  215  253   \n",
              "14   0   0   0   0   0   0   0  157  253  253  253  253  253  253  253  253   \n",
              "15   0   0   0   0   0   0   0  128  253  253  253  253  253  253  253  253   \n",
              "16   0   0   0   0   0   0   0    0   31   19   88   88   58  100  254  254   \n",
              "17   0   0   0   0   0   0   0    0    0    0    0    0    0   18  253  253   \n",
              "18   0   0   0   0   0   0   0    0    0    0    0    0    7  135  253  253   \n",
              "19   0   0   0   0   0   0   0    0    0    0    0    0   45  253  253  235   \n",
              "20   0   0   0   0   0   0   0    0    0    0    0    7  168  253  248   50   \n",
              "21   0   0   0   0   0   0   0    0    0    0    0   48  253  253  159    0   \n",
              "22   0   0   0   0   0   0   0    0    0    0   20  211  253  245   39    0   \n",
              "23   0   0   0   0   0   0   0    0    0    4  149  253  251  128    0    0   \n",
              "24   0   0   0   0   0   0   0    0    0   53  253  253  193    0    0    0   \n",
              "25   0   0   0   0   0   0   0    0    0   35  241  228   43    0    0    0   \n",
              "26   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
              "27   0   0   0   0   0   0   0    0    0    0    0    0    0    0    0    0   \n",
              "\n",
              "     16   17   18   19   20   21   22   23  24  25  26  27  \n",
              "0     0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "1     0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "2     0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "3     0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "4     0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "5     0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "6     0    0    0    0    0   11  157  248  46   0   0   0  \n",
              "7     0    0    0    0   76  231  253  163  27   0   0   0  \n",
              "8     0    0    0   53  239  253  155    4   0   0   0   0  \n",
              "9     0    0   13  224  253  185    6    0   0   0   0   0  \n",
              "10    0    0  152  253  245   36    0    0   0   0   0   0  \n",
              "11    0   47  244  253   95    0    0    0   0   0   0   0  \n",
              "12   84  231  253  253  114    0    0    0   0   0   0   0  \n",
              "13  254  253  253  253  203    0    0    0   0   0   0   0  \n",
              "14  254  253  226  138   34    0    0    0   0   0   0   0  \n",
              "15  254  253   74    0    0    0    0    0   0   0   0   0  \n",
              "16  255  232   12    0    0    0    0    0   0   0   0   0  \n",
              "17  254   44    0    0    0    0    0    0   0   0   0   0  \n",
              "18  186    4    0    0    0    0    0    0   0   0   0   0  \n",
              "19    9    0    0    0    0    0    0    0   0   0   0   0  \n",
              "20    0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "21    0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "22    0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "23    0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "24    0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "25    0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "26    0    0    0    0    0    0    0    0   0   0   0   0  \n",
              "27    0    0    0    0    0    0    0    0   0   0   0   0  "
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.DataFrame(x_train[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "qeoQHB1B8nC7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3) (50000, 1)\n",
            "(10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Must pass 2-d input. shape=(32, 32, 3)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\user\\Desktop\\KT AIVLE 4기\\06. 딥러닝\\2023.09.04_딥러닝_실습자료\\딥러닝_텐서플로우_실습_정답.ipynb 셀 44\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/KT%20AIVLE%204%EA%B8%B0/06.%20%EB%94%A5%EB%9F%AC%EB%8B%9D/2023.09.04_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%94%A5%EB%9F%AC%EB%8B%9D_%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0_%EC%8B%A4%EC%8A%B5_%EC%A0%95%EB%8B%B5.ipynb#X61sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/KT%20AIVLE%204%EA%B8%B0/06.%20%EB%94%A5%EB%9F%AC%EB%8B%9D/2023.09.04_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%94%A5%EB%9F%AC%EB%8B%9D_%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0_%EC%8B%A4%EC%8A%B5_%EC%A0%95%EB%8B%B5.ipynb#X61sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pd\u001b[39m.\u001b[39mset_option(\u001b[39m'\u001b[39m\u001b[39mdisplay.max_columns\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/KT%20AIVLE%204%EA%B8%B0/06.%20%EB%94%A5%EB%9F%AC%EB%8B%9D/2023.09.04_%EB%94%A5%EB%9F%AC%EB%8B%9D_%EC%8B%A4%EC%8A%B5%EC%9E%90%EB%A3%8C/%EB%94%A5%EB%9F%AC%EB%8B%9D_%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0_%EC%8B%A4%EC%8A%B5_%EC%A0%95%EB%8B%B5.ipynb#X61sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(x_train[i])\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    723\u001b[0m             data,\n\u001b[0;32m    724\u001b[0m             index,\n\u001b[0;32m    725\u001b[0m             columns,\n\u001b[0;32m    726\u001b[0m             dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m    727\u001b[0m             copy\u001b[39m=\u001b[39mcopy,\n\u001b[0;32m    728\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    729\u001b[0m         )\n\u001b[0;32m    731\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:329\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    324\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarraylike(values, copy\u001b[39m=\u001b[39mcopy_on_sanitize)\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[0;32m    332\u001b[0m     \u001b[39m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[0;32m    333\u001b[0m     rcf \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m (is_integer_dtype(dtype) \u001b[39mand\u001b[39;00m values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:583\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    581\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[0;32m    582\u001b[0m \u001b[39melif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMust pass 2-d input. shape=\u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    585\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
            "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(32, 32, 3)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.DataFrame(x_train[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "9G3GwSDz9O9P"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[4]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x1ce7de15c90>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = 3\n",
        "print(y_train[i])\n",
        "plt.imshow(x_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTqyU4axweKx"
      },
      "source": [
        "## MNIST 손글씨 분류 - Flatten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "hY9Jd6qw9cC6"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Sl4OVpq2msro"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(50000, 32, 32, 3) (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "# MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "# (60000, 28, 28, 1) (60000,)\n",
        "\n",
        "# CIFAR-10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "# (50000, 28, 28, 1) (50000, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsJqgY5FF7-I",
        "outputId": "d84870f4-c465-45fe-ff60-51e61d69ea6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n",
            "(60000, 784) (60000, 10)\n",
            "(10000, 784) (10000, 10)\n",
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 784)]             0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 84)                65940     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 66790 (260.90 KB)\n",
            "Trainable params: 66790 (260.90 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 5.3844 - accuracy: 0.8362 - val_loss: 0.8942 - val_accuracy: 0.8703\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.8945 - val_loss: 0.4644 - val_accuracy: 0.9158\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.3960 - accuracy: 0.9241 - val_loss: 0.3819 - val_accuracy: 0.9373\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.3047 - accuracy: 0.9379 - val_loss: 0.3081 - val_accuracy: 0.9490\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.2597 - accuracy: 0.9487 - val_loss: 0.3841 - val_accuracy: 0.9385\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.2218 - accuracy: 0.9530 - val_loss: 0.2965 - val_accuracy: 0.9490\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.2039 - accuracy: 0.9578 - val_loss: 0.3348 - val_accuracy: 0.9520\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.9614 - val_loss: 0.3079 - val_accuracy: 0.9490\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.1686 - accuracy: 0.9631 - val_loss: 0.3096 - val_accuracy: 0.9575\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 1s 2ms/step - loss: 0.1577 - accuracy: 0.9662 - val_loss: 0.3151 - val_accuracy: 0.9553\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1ce15b1dc90>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "x_train = x_train.reshape(60000, 28 * 28)\n",
        "x_test = x_test.reshape(10000, 28 * 28)\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "# 모델 준비\n",
        "X = tf.keras.Input(shape=[28 * 28])\n",
        "H = tf.keras.layers.Dense(84, activation=\"swish\")(X)\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=10, validation_split=0.1, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "XLsl_kkKwk2y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "(10000, 28, 28) (10000,)\n",
            "(60000, 28, 28) (60000, 10)\n",
            "(10000, 28, 28) (10000, 10)\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 12, 12)]          0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 12, 5)             65        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 12, 2)             12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77 (308.00 Byte)\n",
            "Trainable params: 77 (308.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test)= tf.keras.datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "# x_train = x_train.reshape(60000, 28 * 28)\n",
        "# x_test = x_test.reshape(10000, 28 * 28)\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "# 모델 준비\n",
        "X = tf.keras.Input(shape=[12, 12])\n",
        "#H = tf.keras.layers.Flatten()(X)\n",
        "H = tf.keras.layers.Dense(5, activation=\"swish\")(X)\n",
        "Y = tf.keras.layers.Dense(2, activation=\"softmax\")(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=10, validation_split=0.1, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PIaWNtty68ku"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4374 - accuracy: 0.9523\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.43735864758491516, 0.9523000121116638]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 평가\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "CkBdgLBSwpP3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      0  1  2  3  4  5  6  7  8  9\n",
            "9538  0  0  0  0  1  0  0  0  0  0\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "[[0.0000000e+00 0.0000000e+00 1.2957460e-30 3.3102528e-24 1.0000000e+00\n",
            "  1.5630066e-19 0.0000000e+00 3.1308307e-11 4.0952330e-09 4.5859010e-09]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 모델 이용\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num = 9538\n",
        "print(y_test[num:num+1])\n",
        "print(model.predict(x_test[num:num+1]))\n",
        "\n",
        "plt.imshow(x_test[num].reshape(28, 28), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy5qoZ2qNYrA"
      },
      "source": [
        "## MNIST 손글씨 분류 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "wg4jIxttwp2O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ej9cxgo4Nekh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (60000, 10)\n",
            "(10000, 28, 28, 1) (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "d0cPSDRZNwxL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 24, 24, 3)         78        \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 20, 20, 6)         456       \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2400)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 84)                201684    \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 203068 (793.23 KB)\n",
            "Trainable params: 203068 (793.23 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation='swish')(X)\n",
        "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation='swish')(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0wRFFDeBN257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "422/422 [==============================] - 9s 21ms/step - loss: 0.8427 - accuracy: 0.8941 - val_loss: 0.1482 - val_accuracy: 0.9558\n",
            "Epoch 2/10\n",
            "422/422 [==============================] - 10s 24ms/step - loss: 0.0895 - accuracy: 0.9734 - val_loss: 0.1412 - val_accuracy: 0.9647\n",
            "Epoch 3/10\n",
            "422/422 [==============================] - 10s 24ms/step - loss: 0.0419 - accuracy: 0.9868 - val_loss: 0.1075 - val_accuracy: 0.9765\n",
            "Epoch 4/10\n",
            "422/422 [==============================] - 10s 25ms/step - loss: 0.0207 - accuracy: 0.9933 - val_loss: 0.1157 - val_accuracy: 0.9762\n",
            "Epoch 5/10\n",
            "422/422 [==============================] - 11s 25ms/step - loss: 0.0127 - accuracy: 0.9958 - val_loss: 0.1147 - val_accuracy: 0.9782\n",
            "Epoch 6/10\n",
            "422/422 [==============================] - 11s 26ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.1335 - val_accuracy: 0.9778\n",
            "Epoch 7/10\n",
            "422/422 [==============================] - 11s 26ms/step - loss: 0.0087 - accuracy: 0.9973 - val_loss: 0.1469 - val_accuracy: 0.9768\n",
            "Epoch 8/10\n",
            "422/422 [==============================] - 11s 26ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.1536 - val_accuracy: 0.9817\n",
            "Epoch 9/10\n",
            "422/422 [==============================] - 11s 26ms/step - loss: 0.0060 - accuracy: 0.9980 - val_loss: 0.1752 - val_accuracy: 0.9795\n",
            "Epoch 10/10\n",
            "422/422 [==============================] - 11s 26ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.2062 - val_accuracy: 0.9745\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x265c3a5fdd0>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "h6OF74HLN3gF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0309 - accuracy: 0.9944\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.030917225405573845, 0.9943833351135254]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 평가\n",
        "model.evaluate(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "pF0EwPHwAOmZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script uvicorn.exe is installed in 'c:\\Users\\user\\anaconda3\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script huggingface-cli.exe is installed in 'c:\\Users\\user\\anaconda3\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The script httpx.exe is installed in 'c:\\Users\\user\\anaconda3\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The scripts gradio.exe and upload_theme.exe are installed in 'c:\\Users\\user\\anaconda3\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.7.1 which is incompatible.\n"
          ]
        }
      ],
      "source": [
        "pip install gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "h9O8sgC3AOiV"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'TypeAliasType' from 'typing_extensions' (c:\\Users\\user\\anaconda3\\Lib\\site-packages\\typing_extensions.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mgr\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgreet\u001b[39m(s_img):\n\u001b[0;32m      5\u001b[0m     \u001b[39m# 흑백으로 변환\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpkgutil\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mcomponents\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minputs\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39minputs\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moutputs\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moutputs\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\components\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgradio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mannotated_image\u001b[39;00m \u001b[39mimport\u001b[39;00m AnnotatedImage\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgradio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m \u001b[39mimport\u001b[39;00m Audio\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgradio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbar_plot\u001b[39;00m \u001b[39mimport\u001b[39;00m BarPlot\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\components\\annotated_image.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgradio_client\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserializing\u001b[39;00m \u001b[39mimport\u001b[39;00m JSONSerializable\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m \u001b[39mimport\u001b[39;00m Image \u001b[39mas\u001b[39;00m _Image  \u001b[39m# using _ to minimize namespace pollution\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgradio\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgradio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcomponents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m IOComponent, _Keywords\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgradio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m warn_style_method_deprecation\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\gradio\\utils.py:45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgradio_client\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mserializing\u001b[39;00m \u001b[39mimport\u001b[39;00m Serializable\n\u001b[1;32m---> 45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, parse_obj_as\n\u001b[0;32m     46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m ParamSpec\n\u001b[0;32m     48\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mgradio\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pydantic\\__init__.py:13\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     FieldSerializationInfo,\n\u001b[0;32m      6\u001b[0m     FieldValidationInfo,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     ValidatorFunctionWrapHandler,\n\u001b[0;32m     11\u001b[0m )\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dataclasses\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_annotated_handlers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     15\u001b[0m     GetCoreSchemaHandler \u001b[39mas\u001b[39;00m GetCoreSchemaHandler,\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_annotated_handlers\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     GetJsonSchemaHandler \u001b[39mas\u001b[39;00m GetJsonSchemaHandler,\n\u001b[0;32m     19\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pydantic\\dataclasses.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Generic, NoReturn, TypeVar, overload\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Literal, dataclass_transform\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m _config, _decorators, _typing_extra\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m _dataclasses \u001b[39mas\u001b[39;00m _pydantic_dataclasses\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_migration\u001b[39;00m \u001b[39mimport\u001b[39;00m getattr_migration\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_decorators.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Literal, TypeAlias, is_typeddict\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m PydanticUserError\n\u001b[1;32m---> 15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfields\u001b[39;00m \u001b[39mimport\u001b[39;00m ComputedFieldInfo\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_core_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_type_ref\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal_dataclass\u001b[39;00m \u001b[39mimport\u001b[39;00m slots_true\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pydantic\\fields.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m \u001b[39mimport\u001b[39;00m PydanticUndefined\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Unpack\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m types\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m _decorators, _fields, _generics, _internal_dataclass, _repr, _typing_extra, _utils\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39merrors\u001b[39;00m \u001b[39mimport\u001b[39;00m PydanticUserError\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pydantic\\types.py:34\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m \u001b[39mimport\u001b[39;00m CoreSchema, PydanticCustomError, PydanticKnownError, core_schema\n\u001b[0;32m     32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Annotated, Literal, Protocol, deprecated\n\u001b[1;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_internal\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     35\u001b[0m     _annotated_handlers,\n\u001b[0;32m     36\u001b[0m     _fields,\n\u001b[0;32m     37\u001b[0m     _internal_dataclass,\n\u001b[0;32m     38\u001b[0m     _known_annotated_metadata,\n\u001b[0;32m     39\u001b[0m     _utils,\n\u001b[0;32m     40\u001b[0m     _validators,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_migration\u001b[39;00m \u001b[39mimport\u001b[39;00m getattr_migration\n\u001b[0;32m     43\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfigDict\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_fields.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mannotated_types\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseMetadata\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m \u001b[39mimport\u001b[39;00m PydanticUndefined\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _typing_extra\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_config\u001b[39;00m \u001b[39mimport\u001b[39;00m ConfigWrapper\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_repr\u001b[39;00m \u001b[39mimport\u001b[39;00m Representation\n",
            "File \u001b[1;32mc:\\Users\\user\\anaconda3\\Lib\\site-packages\\pydantic\\_internal\\_typing_extra.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtypes\u001b[39;00m \u001b[39mimport\u001b[39;00m GetSetDescriptorType\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Any, ForwardRef\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Annotated, Final, Literal, TypeAliasType, TypeGuard, get_args, get_origin\n\u001b[0;32m     15\u001b[0m \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     16\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_dataclasses\u001b[39;00m \u001b[39mimport\u001b[39;00m StandardDataclass\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name 'TypeAliasType' from 'typing_extensions' (c:\\Users\\user\\anaconda3\\Lib\\site-packages\\typing_extensions.py)"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "def greet(s_img):\n",
        "    # 흑백으로 변환\n",
        "    s_img = s_img.convert('L')\n",
        "\n",
        "    # 크기를 변경\n",
        "    img = s_img.resize((28, 28))\n",
        "\n",
        "    # 다시 numpy array로 변환\n",
        "    img = np.full((28, 28), 255.) - np.array(img)\n",
        "\n",
        "    return model.predict(img.reshape(1, 28, 28)), s_img\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=gr.Image(source=\"canvas\", type=\"pil\"),\n",
        "    outputs=[\"text\", \"image\"]\n",
        ")\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkiCgBS3XzqP"
      },
      "source": [
        "## MNIST 손글씨 분류 - MaxPool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "lCMXPDtxN44-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "5dA-OA3kX77h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1) (60000, 10)\n",
            "(10000, 28, 28, 1) (10000, 10)\n"
          ]
        }
      ],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "00-OP8p9X9k6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 24, 24, 3)         78        \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 12, 12, 3)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 6)           456       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 4, 4, 6)           0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 96)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 84)                8148      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9532 (37.23 KB)\n",
            "Trainable params: 9532 (37.23 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "H = tf.keras.layers.Conv2D(3, 5, activation='swish')(X)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(6, 5, activation='swish')(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXlmYTmOYemO"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNVV-74L19f7"
      },
      "source": [
        "### 클래스 속성 vs 메쏘드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuB395Ukb8Mr"
      },
      "outputs": [],
      "source": [
        "class Animal:\n",
        "    def __init__(self, name, type):\n",
        "        self.name = name\n",
        "        self.type = type\n",
        "\n",
        "    def cry(self):\n",
        "        if self.type == \"고양이\":\n",
        "            return \"야옹\"\n",
        "        elif self.type == \"개\":\n",
        "            return \"멍멍\"\n",
        "\n",
        "a = Animal(\"키키\", \"개\")\n",
        "b = Animal(\"지지\", \"고양이\")\n",
        "\n",
        "print(a.cry())\n",
        "print(b.cry())\n",
        "print(a.name, a.type)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\n",
        "print(df.shape)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhenEMxn8iNC"
      },
      "source": [
        "# CNN Models - LeNet5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MHkbH7ucZmg"
      },
      "source": [
        "## fashion mnist - 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouGq3_nK2DKU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiGlC-Cybkhf"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaRvMbiGbsmG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "num = 1\n",
        "print(y_train[num])\n",
        "plt.imshow(x_train[num], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgQ2VWFd1Dqi"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "# 텐서플로우의 원핫인코딩 함수\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ZxYZD52LZe"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "H = tf.keras.layers.Conv2D(3, 5, activation=\"swish\")(X)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(6, 5, activation=\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(84, activation=\"swish\")(H)\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D4H_Ola3JCC"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyNCmytR3J1o"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCrE0h778J5a"
      },
      "source": [
        "## LeNet-5 + fashion mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-7mr_qxCmFO"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "# 텐서플로우의 원핫인코딩 함수\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn_MHtXp3LCr"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "\n",
        "H = tf.keras.layers.Conv2D(6, 5, padding=\"same\")(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Conv2D(16, 5)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(120)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(84)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKQu5Yg28pVH"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53cumPp09C-6"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-E-uTEBwFJ"
      },
      "source": [
        "## Lenet-5 + cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKVAh5uy9RrU"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# 텐서플로우의 원핫인코딩 함수\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb0lYLGQB2mP"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[32, 32, 3])\n",
        "\n",
        "H = tf.keras.layers.Conv2D(6, 5)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Conv2D(16, 5)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(120)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(84)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_KOw6aeCLqj"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxyFMSGvMq-p"
      },
      "source": [
        "## Lenet-5 + cifar10 + dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8tokzHLCPPe"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# normalize\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# 텐서플로우의 원핫인코딩 함수\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDRiRlggM5xs"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[32, 32, 3])\n",
        "\n",
        "H = tf.keras.layers.Conv2D(6, 5)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "# H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(6, 5, strides=2, padding=\"same\")(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Conv2D(16, 5)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "# H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(16, 5, strides=2, padding=\"same\")(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "\n",
        "H = tf.keras.layers.Dropout(0.6)(H)\n",
        "H = tf.keras.layers.Dense(120)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(84)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV1sXf8sNKxk"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "es = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "model.fit(x_train, y_train, epochs=100000, batch_size=128, validation_split=0.1, callbacks=[es])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezFWHTskVBIP"
      },
      "source": [
        "## Data Augmentation\n",
        "- 256x256 이미지 10,000장을 학습용 이미지로 제공\n",
        "- 224x224로 crop 하여 1장의 이미지에서 1024 이미지를 추출\n",
        "- 좌우반전을 더해 총 2048만 장의 이미지로 학습을 하게 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVLkaNNHVA2i"
      },
      "outputs": [],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    rotation_range=0.1,\n",
        ")\n",
        "train_ds = datagen.flow(x_train[:40000], y_train[:40000], batch_size=128)\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((x_train[40000:], y_train[40000:])).batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC21T2lANQpA"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(train_ds))\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHzMVg53YXiL"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "es = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "model.fit(train_ds, validation_data=valid_ds, epochs=100000, callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs77xTTIZS2U"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PelELvulPz1f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
