{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNr2tQvUu1dm"
      },
      "source": [
        "# 텐서플로우 - 표"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCcdJK04KvPW"
      },
      "source": [
        "## 첫번째 딥러닝 - 레모네이드 판매 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hU9rb2WJkdv"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터를 준비합니다.\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/lemonade.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCkctOvKLKtl"
      },
      "outputs": [],
      "source": [
        "x_train = df[['온도']]\n",
        "y_train = df[['판매량']]\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQvAw26kLZwC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 모델을 준비합니다.\n",
        "X = tf.keras.Input(shape=[1])\n",
        "Y = tf.keras.layers.Dense(1)(X)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGeNTbtgROXd"
      },
      "outputs": [],
      "source": [
        "# 데이터로 모델을 학습합니다.\n",
        "model.fit(x_train, y_train, epochs=1000, verbose=0)\n",
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zU8DwVleRY2j"
      },
      "outputs": [],
      "source": [
        "# 모델을 이용합니다.\n",
        "y_pred = model.predict([[15]])\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwUwBJb4RvLU"
      },
      "outputs": [],
      "source": [
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYre2lCEXFNc"
      },
      "outputs": [],
      "source": [
        "온도 = 15\n",
        "판매량 = 1.9593028 * 온도 + 0.93252075\n",
        "print(판매량)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_JT3TXLYJpe"
      },
      "source": [
        "## 두번째 딥러닝 - 보스턴 집값 예측"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-WKUMggXRwB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터를 준비합니다.\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(df.columns)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSPxRFlcZsv-"
      },
      "outputs": [],
      "source": [
        "x_train = df[['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis',\n",
        "              'rad', 'tax','ptratio', 'b', 'lstat']]\n",
        "y_train = df[['medv']]\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0pul1UrZ7tT"
      },
      "outputs": [],
      "source": [
        "# 모델을 준비합니다.\n",
        "X = tf.keras.Input(shape=[13])\n",
        "Y = tf.keras.layers.Dense(1)(X)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='mse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSknTwuVaXSh"
      },
      "outputs": [],
      "source": [
        "# 모델을 학습합니다.\n",
        "model.fit(x_train, y_train, epochs=1000, verbose=0)\n",
        "model.fit(x_train, y_train, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNzI9LmgaYWY"
      },
      "outputs": [],
      "source": [
        "# 모델을 이용합니다.\n",
        "print(y_train[0:5])\n",
        "model.predict(x_train[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0p6JPsFa2Zl"
      },
      "outputs": [],
      "source": [
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQhFkTS4lWkA"
      },
      "source": [
        "## 세번째 딥러닝 - 아이리스 품종 분류"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "maRK67q8e2PJ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터를 준비합니다.\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(df.columns)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WN7VYCZ7la94"
      },
      "outputs": [],
      "source": [
        "df_onehot = pd.get_dummies(df)\n",
        "print(df_onehot.columns)\n",
        "df_onehot.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZX-JSqsslgqE"
      },
      "outputs": [],
      "source": [
        "x_train = df_onehot[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
        "y_train = df_onehot[['품종_setosa', '품종_versicolor', '품종_virginica']]\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfPta1HzlvhD"
      },
      "outputs": [],
      "source": [
        "# 모델을 완성합니다\n",
        "X = tf.keras.Input(shape=[4])\n",
        "Y = tf.keras.layers.Dense(3, activation='softmax')(X)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "# activation이 sigmoid일 때는 loss는 binary_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATqMV_oTvFmg"
      },
      "outputs": [],
      "source": [
        "# 모델을 학습합니다.\n",
        "model.fit(x_train, y_train, epochs=500, verbose=0)\n",
        "model.fit(x_train, y_train, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygm2Cc9NvGgF"
      },
      "outputs": [],
      "source": [
        "# 모델을 이용합니다.\n",
        "model.predict(x_train[-5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXRLAtk9vHrB"
      },
      "outputs": [],
      "source": [
        "y_train[-5:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-IBlVLZwrRG"
      },
      "outputs": [],
      "source": [
        "model.get_weights()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "x1, x2, x3, x4 = 5.1, 3.5, 1.4, 0.2\n",
        "\n",
        "y1 = 0.64499074 * x1 + 1.1522864 * x2 + -1.3698963 * x3 + -2.0730422 * x4 + 0.46010897\n",
        "y2 = 0.5810931  * x1 + -0.32803437 * x2 + -0.03559899 * x3 + -0.20144817 * x4 + 0.04075331\n",
        "y3 = 0.07686843 * x1 + -0.79343975 * x2 + 0.5791432 * x3 + 0.89187205 * x4 + -0.16803536\n",
        "\n",
        "print(y1, y2, y3)\n",
        "\n",
        "ey1 = math.e ** y1\n",
        "ey2 = math.e ** y2\n",
        "ey3 = math.e ** y3\n",
        "\n",
        "py1 = ey1 / (ey1 + ey2 + ey3)\n",
        "py2 = ey2 / (ey1 + ey2 + ey3)\n",
        "py3 = ey3 / (ey1 + ey2 + ey3)\n",
        "\n",
        "print(py1, py2, py3)\n",
        "# [9.7463906e-01, 2.4484634e-02, 8.7642501e-04],"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "y1 = 1.8\n",
        "y2 = 2.5\n",
        "y3 = -1.1\n",
        "\n",
        "ey1 = math.e ** y1\n",
        "ey2 = math.e ** y2\n",
        "ey3 = math.e ** y3\n",
        "\n",
        "py1 = ey1 / (ey1 + ey2 + ey3)\n",
        "py2 = ey2 / (ey1 + ey2 + ey3)\n",
        "py3 = ey3 / (ey1 + ey2 + ey3)\n",
        "\n",
        "print(py1, py2, py3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkUFbX24UkHH"
      },
      "source": [
        "## 네번째 딥러닝 - 진짜 딥러닝 히든 레이어"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22y8JO2VUsN6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUqTWFAIxZWI"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_train = df['medv']\n",
        "x_train = df.drop(columns='medv')\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 스케일링\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = MinMaxScaler()\n",
        "\n",
        "# x= scaler.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TlnjTcW3Utua"
      },
      "outputs": [],
      "source": [
        "# 모델 준비\n",
        "X = tf.keras.Input(shape=[13])\n",
        "H = tf.keras.layers.Dense(128, activation='swish')(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Dense(5, activation='swish')(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "Y = tf.keras.layers.Dense(1)(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='mse')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1Z9FuJUUvBQ"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 실습. 아이리스 딥 뉴럴넷 구성하기\n",
        " - 미션 : accuract 100% 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# 데이터를 준비합니다.\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/iris.csv\"\n",
        "df = pd.read_csv(path)\n",
        "print(df.columns)\n",
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_onehot = pd.get_dummies(df)\n",
        "print(df_onehot.columns)\n",
        "df_onehot.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = df_onehot[['꽃잎길이', '꽃잎폭', '꽃받침길이', '꽃받침폭']]\n",
        "y_train = df_onehot[['품종_setosa', '품종_versicolor', '품종_virginica']]\n",
        "print(x_train.shape, y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 완성합니다\n",
        "X = tf.keras.Input(shape=[4])\n",
        "H = tf.keras.layers.Dense(32, activation='swish')(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Dense(32, activation='swish')(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "Y = tf.keras.layers.Dense(3, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='categorical_crossentropy', metrics=\"accuracy\")\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 학습합니다.\n",
        "# model.fit(x_train, y_train, epochs=500, batch_size=150)\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 현재 모델 성능 확인\n",
        "model.evaluate(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gradient Tapes\n",
        "- https://www.tensorflow.org/api_docs/python/tf/GradientTape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(506, 13)\n",
            "(506,)\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 12)]              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 65        \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 12        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 77 (308.00 Byte)\n",
            "Trainable params: 77 (308.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# 데이터 준비\n",
        "path = \"https://raw.githubusercontent.com/blackdew/ml-tensorflow/master/data/csv/boston.csv\"\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "df.head()\n",
        "y_train = df['medv']\n",
        "x_train = df.drop(columns='medv')\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "# 모델 준비\n",
        "X = tf.keras.Input(shape=[12])\n",
        "H = tf.keras.layers.Dense(5, activation='swish')(X)\n",
        "#H = tf.keras.layers.BatchNormalization()(H)\n",
        "#H = tf.keras.layers.Dense(5, activation='swish')(H)\n",
        "#H = tf.keras.layers.BatchNormalization()(H)\n",
        "Y = tf.keras.layers.Dense(2)(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='mse')\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "4/4 [==============================] - 1s 3ms/step - loss: 585.9155\n",
            "Epoch 2/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 576.5739\n",
            "Epoch 3/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 573.0053\n",
            "Epoch 4/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 570.4356\n",
            "Epoch 5/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 568.3157\n",
            "Epoch 6/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 565.5970\n",
            "Epoch 7/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 563.0086\n",
            "Epoch 8/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 560.1757\n",
            "Epoch 9/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 558.4782\n",
            "Epoch 10/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 556.8883\n",
            "Epoch 11/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 554.0436\n",
            "Epoch 12/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 552.4371\n",
            "Epoch 13/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 549.7084\n",
            "Epoch 14/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 547.2982\n",
            "Epoch 15/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 544.7607\n",
            "Epoch 16/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 543.4152\n",
            "Epoch 17/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 541.1733\n",
            "Epoch 18/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 539.3895\n",
            "Epoch 19/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 537.4152\n",
            "Epoch 20/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 536.4197\n",
            "Epoch 21/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 534.0731\n",
            "Epoch 22/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 533.5893\n",
            "Epoch 23/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 531.8503\n",
            "Epoch 24/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 529.4879\n",
            "Epoch 25/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 528.1232\n",
            "Epoch 26/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 527.2889\n",
            "Epoch 27/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 526.2772\n",
            "Epoch 28/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 524.6678\n",
            "Epoch 29/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 524.0212\n",
            "Epoch 30/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 522.6490\n",
            "Epoch 31/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 521.0251\n",
            "Epoch 32/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 518.5273\n",
            "Epoch 33/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 517.2657\n",
            "Epoch 34/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 515.8802\n",
            "Epoch 35/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 514.7110\n",
            "Epoch 36/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 512.9525\n",
            "Epoch 37/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 511.3164\n",
            "Epoch 38/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 509.7238\n",
            "Epoch 39/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 510.5504\n",
            "Epoch 40/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 506.8734\n",
            "Epoch 41/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 505.7840\n",
            "Epoch 42/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 504.3287\n",
            "Epoch 43/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 504.9571\n",
            "Epoch 44/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 501.9958\n",
            "Epoch 45/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 500.2776\n",
            "Epoch 46/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 499.1158\n",
            "Epoch 47/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 497.6229\n",
            "Epoch 48/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 497.8479\n",
            "Epoch 49/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 495.0164\n",
            "Epoch 50/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 493.5751\n",
            "Epoch 51/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 492.8565\n",
            "Epoch 52/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 490.8166\n",
            "Epoch 53/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 491.0018\n",
            "Epoch 54/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 488.2876\n",
            "Epoch 55/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 488.3130\n",
            "Epoch 56/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 485.6644\n",
            "Epoch 57/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 483.6169\n",
            "Epoch 58/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 482.8035\n",
            "Epoch 59/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 481.0296\n",
            "Epoch 60/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 479.9278\n",
            "Epoch 61/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 479.4977\n",
            "Epoch 62/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 476.3828\n",
            "Epoch 63/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 476.7439\n",
            "Epoch 64/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 475.1154\n",
            "Epoch 65/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 472.6203\n",
            "Epoch 66/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 471.0644\n",
            "Epoch 67/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 471.0291\n",
            "Epoch 68/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 467.6716\n",
            "Epoch 69/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 468.2321\n",
            "Epoch 70/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 464.9017\n",
            "Epoch 71/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 463.8174\n",
            "Epoch 72/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 465.2749\n",
            "Epoch 73/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 461.5693\n",
            "Epoch 74/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 460.1128\n",
            "Epoch 75/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 458.8247\n",
            "Epoch 76/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 456.3011\n",
            "Epoch 77/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 455.6798\n",
            "Epoch 78/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 455.1587\n",
            "Epoch 79/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 452.5030\n",
            "Epoch 80/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 450.3791\n",
            "Epoch 81/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 448.6689\n",
            "Epoch 82/300\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 449.1070\n",
            "Epoch 83/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 447.9389\n",
            "Epoch 84/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 444.4754\n",
            "Epoch 85/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 444.0645\n",
            "Epoch 86/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 443.4481\n",
            "Epoch 87/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 440.3595\n",
            "Epoch 88/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 440.9666\n",
            "Epoch 89/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 438.3212\n",
            "Epoch 90/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 437.2458\n",
            "Epoch 91/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 435.4719\n",
            "Epoch 92/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 433.4003\n",
            "Epoch 93/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 431.1980\n",
            "Epoch 94/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 431.2457\n",
            "Epoch 95/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 430.2039\n",
            "Epoch 96/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 428.2186\n",
            "Epoch 97/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 426.6547\n",
            "Epoch 98/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 424.2218\n",
            "Epoch 99/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 424.0077\n",
            "Epoch 100/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 421.4498\n",
            "Epoch 101/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 422.5648\n",
            "Epoch 102/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 417.8786\n",
            "Epoch 103/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 417.3450\n",
            "Epoch 104/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 415.4849\n",
            "Epoch 105/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 415.9340\n",
            "Epoch 106/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 413.1225\n",
            "Epoch 107/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 409.8893\n",
            "Epoch 108/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 410.0583\n",
            "Epoch 109/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 409.7448\n",
            "Epoch 110/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 406.1953\n",
            "Epoch 111/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 404.5001\n",
            "Epoch 112/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 405.4558\n",
            "Epoch 113/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 402.9050\n",
            "Epoch 114/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 400.6305\n",
            "Epoch 115/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 402.0246\n",
            "Epoch 116/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 399.3150\n",
            "Epoch 117/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 394.7705\n",
            "Epoch 118/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 394.5568\n",
            "Epoch 119/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 392.7343\n",
            "Epoch 120/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 392.2418\n",
            "Epoch 121/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 389.6837\n",
            "Epoch 122/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 387.8909\n",
            "Epoch 123/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 386.1738\n",
            "Epoch 124/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 385.4657\n",
            "Epoch 125/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 383.0617\n",
            "Epoch 126/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 380.7629\n",
            "Epoch 127/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 383.8487\n",
            "Epoch 128/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 379.2089\n",
            "Epoch 129/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 376.0110\n",
            "Epoch 130/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 376.0928\n",
            "Epoch 131/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 376.7570\n",
            "Epoch 132/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 371.7796\n",
            "Epoch 133/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 370.7766\n",
            "Epoch 134/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 368.3526\n",
            "Epoch 135/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 368.4240\n",
            "Epoch 136/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 366.1172\n",
            "Epoch 137/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 364.6552\n",
            "Epoch 138/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 364.3573\n",
            "Epoch 139/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 365.0348\n",
            "Epoch 140/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 361.0070\n",
            "Epoch 141/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 358.4754\n",
            "Epoch 142/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 360.3788\n",
            "Epoch 143/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 355.8551\n",
            "Epoch 144/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 354.8714\n",
            "Epoch 145/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 355.1200\n",
            "Epoch 146/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 351.0096\n",
            "Epoch 147/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 350.6019\n",
            "Epoch 148/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 349.0681\n",
            "Epoch 149/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 346.3900\n",
            "Epoch 150/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 344.8154\n",
            "Epoch 151/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 344.0388\n",
            "Epoch 152/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 343.3356\n",
            "Epoch 153/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 340.2596\n",
            "Epoch 154/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 340.3176\n",
            "Epoch 155/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 338.9850\n",
            "Epoch 156/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 336.8374\n",
            "Epoch 157/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 334.3878\n",
            "Epoch 158/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 335.6852\n",
            "Epoch 159/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 331.3636\n",
            "Epoch 160/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 329.2310\n",
            "Epoch 161/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 328.2291\n",
            "Epoch 162/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 326.6232\n",
            "Epoch 163/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 330.6768\n",
            "Epoch 164/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 323.8608\n",
            "Epoch 165/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 321.9723\n",
            "Epoch 166/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 322.3644\n",
            "Epoch 167/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 318.5579\n",
            "Epoch 168/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 317.9832\n",
            "Epoch 169/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 315.8882\n",
            "Epoch 170/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 313.8249\n",
            "Epoch 171/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 311.2488\n",
            "Epoch 172/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 311.6861\n",
            "Epoch 173/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 310.4057\n",
            "Epoch 174/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 307.6141\n",
            "Epoch 175/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 307.9010\n",
            "Epoch 176/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 306.6570\n",
            "Epoch 177/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 302.0258\n",
            "Epoch 178/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 303.0616\n",
            "Epoch 179/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 303.7790\n",
            "Epoch 180/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 298.7462\n",
            "Epoch 181/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 296.6934\n",
            "Epoch 182/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 296.0412\n",
            "Epoch 183/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 295.9373\n",
            "Epoch 184/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 294.1306\n",
            "Epoch 185/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 291.3795\n",
            "Epoch 186/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 289.4307\n",
            "Epoch 187/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 288.7618\n",
            "Epoch 188/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 288.1500\n",
            "Epoch 189/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 285.2996\n",
            "Epoch 190/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 282.0760\n",
            "Epoch 191/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 282.8004\n",
            "Epoch 192/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 279.9313\n",
            "Epoch 193/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 279.0675\n",
            "Epoch 194/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 276.7472\n",
            "Epoch 195/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 275.3554\n",
            "Epoch 196/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 273.5450\n",
            "Epoch 197/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 271.5757\n",
            "Epoch 198/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 274.4406\n",
            "Epoch 199/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 270.7211\n",
            "Epoch 200/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 267.9964\n",
            "Epoch 201/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 266.9162\n",
            "Epoch 202/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 264.3517\n",
            "Epoch 203/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 265.9881\n",
            "Epoch 204/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 262.3776\n",
            "Epoch 205/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 260.1486\n",
            "Epoch 206/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 260.2138\n",
            "Epoch 207/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 255.5873\n",
            "Epoch 208/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 254.0754\n",
            "Epoch 209/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 254.7841\n",
            "Epoch 210/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 253.4558\n",
            "Epoch 211/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 249.5683\n",
            "Epoch 212/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 249.1110\n",
            "Epoch 213/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 246.2560\n",
            "Epoch 214/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 247.3898\n",
            "Epoch 215/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 244.4284\n",
            "Epoch 216/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 244.0747\n",
            "Epoch 217/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 241.1616\n",
            "Epoch 218/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 240.8429\n",
            "Epoch 219/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 237.7073\n",
            "Epoch 220/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 234.9594\n",
            "Epoch 221/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 234.6596\n",
            "Epoch 222/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 233.0835\n",
            "Epoch 223/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 232.3605\n",
            "Epoch 224/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 230.7018\n",
            "Epoch 225/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 229.8532\n",
            "Epoch 226/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 227.5136\n",
            "Epoch 227/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 225.1303\n",
            "Epoch 228/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 222.8060\n",
            "Epoch 229/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 223.6944\n",
            "Epoch 230/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 222.0558\n",
            "Epoch 231/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 217.5124\n",
            "Epoch 232/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 216.5016\n",
            "Epoch 233/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 217.3808\n",
            "Epoch 234/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 215.5870\n",
            "Epoch 235/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 213.0798\n",
            "Epoch 236/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 213.6425\n",
            "Epoch 237/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 209.8883\n",
            "Epoch 238/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 208.8734\n",
            "Epoch 239/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 206.7862\n",
            "Epoch 240/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 205.4802\n",
            "Epoch 241/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 207.2182\n",
            "Epoch 242/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 201.9249\n",
            "Epoch 243/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 199.7759\n",
            "Epoch 244/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 200.2419\n",
            "Epoch 245/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 197.7194\n",
            "Epoch 246/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 195.3624\n",
            "Epoch 247/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 194.8313\n",
            "Epoch 248/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 194.7092\n",
            "Epoch 249/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 190.4696\n",
            "Epoch 250/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 188.7596\n",
            "Epoch 251/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 188.3022\n",
            "Epoch 252/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 186.1732\n",
            "Epoch 253/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 185.0839\n",
            "Epoch 254/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 184.2437\n",
            "Epoch 255/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 183.2674\n",
            "Epoch 256/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 184.6487\n",
            "Epoch 257/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 180.8319\n",
            "Epoch 258/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 177.3502\n",
            "Epoch 259/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 176.4483\n",
            "Epoch 260/300\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 175.6173\n",
            "Epoch 261/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 174.8645\n",
            "Epoch 262/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 172.5656\n",
            "Epoch 263/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 168.3951\n",
            "Epoch 264/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 167.3998\n",
            "Epoch 265/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 166.4712\n",
            "Epoch 266/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 167.3660\n",
            "Epoch 267/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 165.0214\n",
            "Epoch 268/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 161.8453\n",
            "Epoch 269/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 160.2896\n",
            "Epoch 270/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 160.4874\n",
            "Epoch 271/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 157.9327\n",
            "Epoch 272/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 160.1758\n",
            "Epoch 273/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 156.0550\n",
            "Epoch 274/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 154.0604\n",
            "Epoch 275/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 154.3445\n",
            "Epoch 276/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 152.8355\n",
            "Epoch 277/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 148.5929\n",
            "Epoch 278/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 147.6145\n",
            "Epoch 279/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 147.8599\n",
            "Epoch 280/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 145.7021\n",
            "Epoch 281/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 143.7554\n",
            "Epoch 282/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 141.6161\n",
            "Epoch 283/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 139.7890\n",
            "Epoch 284/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 139.7398\n",
            "Epoch 285/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 137.5100\n",
            "Epoch 286/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 135.9587\n",
            "Epoch 287/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 134.7181\n",
            "Epoch 288/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 134.0383\n",
            "Epoch 289/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 133.9904\n",
            "Epoch 290/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 131.9808\n",
            "Epoch 291/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 128.2954\n",
            "Epoch 292/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 128.8715\n",
            "Epoch 293/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 126.8990\n",
            "Epoch 294/300\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 125.5703\n",
            "Epoch 295/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 123.8247\n",
            "Epoch 296/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 121.5945\n",
            "Epoch 297/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 121.4679\n",
            "Epoch 298/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 120.4847\n",
            "Epoch 299/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 118.2166\n",
            "Epoch 300/300\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 117.7879\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x197deb84250>"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=300, batch_size=150)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 준비합니다.\n",
        "# X = tf.keras.Input(shape=[28, 28])\n",
        "# H = tf.keras.layers.Flatten()(X)\n",
        "# H = tf.keras.layers.Dense(64, activation=tf.keras.activations.swish)(H)\n",
        "# H = tf.keras.layers.BatchNormalization(H)\n",
        "# H = tf.keras.layers.Dense(20, activation=tf.keras.activations.swish)(H)\n",
        "# H = tf.keras.layers.BatchNormalization(H)\n",
        "# Y = tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)(H)\n",
        "# model = tf.keras.Model(X, Y)\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "#               # loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "#               # metrics=tf.keras.metrics.sparse_categorical_accuracy,\n",
        "#               metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "# model.summary()\n",
        "\n",
        "class MyFashionMNISTModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MyFashionMNISTModel, self).__init__(**kwargs)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation=\"swish\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.dense2 = tf.keras.layers.Dense(20, activation=\"swish\")\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.dense3 = tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "\n",
        "    def call(self, X):\n",
        "        H = self.flatten(X)\n",
        "        H = self.dense1(H)\n",
        "        H = self.bn1(H)\n",
        "        H = self.dense2(H)\n",
        "        H = self.bn2(H)\n",
        "        Y = self.dense3(H)\n",
        "        return Y\n",
        "\n",
        "model = MyFashionMNISTModel()\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.build(input_shape=[28, 28])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "999 tf.Tensor(84.47903, shape=(), dtype=float32)\n",
            "16/16 [==============================] - 0s 1ms/step - loss: 85.4059\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "85.40586853027344"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 이용\n",
        "# 이거 강사님이 문제 있다고 했음 뭔 문제인지 모른대 아놔;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
        "loss = tf.keras.losses.MeanSquaredError()\n",
        "optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "for e in range(1000):\n",
        "    with tf.GradientTape() as tape:\n",
        "        pred = model(x_train.values, training=True)\n",
        "        cost = loss(y_train, pred)\n",
        "    grad = tape.gradient(cost, model.trainable_weights)\n",
        "    optim.apply_gradients(zip(grad, model.trainable_weights))\n",
        "print(e, cost)\n",
        "\n",
        "model.evaluate(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSvZMqB4u_Co"
      },
      "source": [
        "## 텐서플로우 CNN - 이미지"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 차원의 이해"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1차원 형태\n",
        "x1 = np.array([1, 2, 3, 4])\n",
        "print(x1.shape, x1.ndim)\n",
        "\n",
        "# 2차원 형태 = 표\n",
        "x1 = np.array([1, 2, 3, 4])\n",
        "x2 = np.array([1, 2, 3, 4])\n",
        "x3 = np.array([1, 2, 3, 4])\n",
        "iris = np.array([x1, x2, x3])\n",
        "print(iris.shape, iris.ndim)\n",
        "\n",
        "# 4차원 공간에 데이터 포인트 3개 찍을 수 있는 데이터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2차원 형태 - 흑백이미지\n",
        "img1 = np.array([[1, 2],\n",
        "                 [3, 4]])\n",
        "print(img1.shape, img1.ndim)\n",
        "\n",
        "# 3차원 형태\n",
        "img1 = np.array([[1, 2],\n",
        "                 [3, 4]])\n",
        "img2 = np.array([[1, 2],\n",
        "                 [3, 4]])\n",
        "img3 = np.array([[1, 2],\n",
        "                 [3, 4]])\n",
        "\n",
        "imgs = np.array([img1, img2, img3])\n",
        "print(imgs.shape, imgs.ndim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M-SDI-l4XI8"
      },
      "source": [
        "### 차원수 - 포함관계"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vco38YBUw64"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "d1 = np.array([1, 2, 3])\n",
        "d1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bHutcv84mVo"
      },
      "outputs": [],
      "source": [
        "d2 = np.array([d1, d1, d1, d1, d1])\n",
        "d2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k64CyEEN4tqf"
      },
      "outputs": [],
      "source": [
        "d3 = np.array([d2, d2, d2, d2])\n",
        "d3.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX6j0SLM41m2"
      },
      "outputs": [],
      "source": [
        "d4 = np.array([d3, d3])\n",
        "d4.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH4UgVgR7Iv7"
      },
      "source": [
        "### 이미지 데이터 구경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJNG0ZLE473s"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DY2TcInS7Qy2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "i = 2451\n",
        "print(y_train[i])\n",
        "plt.imshow(x_train[i], cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0YhaTo172ko"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.DataFrame(x_train[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeoQHB1B8nC7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G3GwSDz9O9P"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "i = 3\n",
        "print(y_train[i])\n",
        "plt.imshow(x_train[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 스스로 실습!!!! Fashion Mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "# 표로 만들기\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "# 원핫인코딩\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 준비합니다.\n",
        "X = tf.keras.Input(shape=[784])\n",
        "H = tf.keras.layers.Dense(128, activation='swish')(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Dropout(0.3)(H)\n",
        "H = tf.keras.layers.Dense(32, activation='swish')(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Dropout(0.3)(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss='categorical_crossentropy', metrics='accuracy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 학습합니다.\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=10,\n",
        "          validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 평가합니다.\n",
        "model.evaluate(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#모델을 이용합니다.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num = 9\n",
        "print(y_test[num:num+1])\n",
        "print(model.predict(x_test[num:num+1]))\n",
        "\n",
        "plt.imshow(x_test[num].reshape(28, 28), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 준비합니다.\n",
        "# X = tf.keras.Input(shape=[28, 28])\n",
        "# H = tf.keras.layers.Flatten()(X)\n",
        "# H = tf.keras.layers.Dense(64, activation=tf.keras.activations.swish)(H)\n",
        "# H = tf.keras.layers.BatchNormalization(H)\n",
        "# H = tf.keras.layers.Dense(20, activation=tf.keras.activations.swish)(H)\n",
        "# H = tf.keras.layers.BatchNormalization(H)\n",
        "# Y = tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)(H)\n",
        "# model = tf.keras.Model(X, Y)\n",
        "# model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "#               # loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "#               # metrics=tf.keras.metrics.sparse_categorical_accuracy,\n",
        "#               metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "# model.summary()\n",
        "\n",
        "# loss = tf.keras.losses.MeanSquaredError()\n",
        "# optim = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# for e in range(1000):\n",
        "#     with tf.GradientTape() as tape:\n",
        "#         pred = model(독립.values, training=True)\n",
        "#         cost = loss(종속, pred)\n",
        "#     grad = tape.gradient(cost, model.trainable_weights)\n",
        "#     optim.apply_gradients(zip(grad, model.trainable_weights))\n",
        "#     print(e, cost)\n",
        "\n",
        "class MyFashionMNISTModel(tf.keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(MyFashionMNISTModel, self).__init__(**kwargs)\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation=\"swish\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.dense2 = tf.keras.layers.Dense(20, activation=\"swish\")\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.dense3 = tf.keras.layers.Dense(10, activation=\"softmax\")\n",
        "\n",
        "    def l\n",
        "\n",
        "    def call(self, X):\n",
        "        H = self.flatten(X)\n",
        "        H = self.dense1(H)\n",
        "        H = self.bn1(H)\n",
        "        H = self.dense2(H)\n",
        "        H = self.bn2(H)\n",
        "        Y = self.dense3(H)\n",
        "        return Y\n",
        "\n",
        "    def train_step(self, batch):\n",
        "        x_batch, y_batch = batch\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x_batch, training=True)\n",
        "            loss = self.compiled_loss(y_batch, y_pred)\n",
        "\n",
        "        grad = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grad, self.trainable_weights))\n",
        "\n",
        "        self.compiled_metrics.update_state(y_batch, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "    def test_step(self, batch):\n",
        "        x_batch, y_batch = batch\n",
        "        y_pred = self(x_batch)\n",
        "\n",
        "        self.compiled_metrics.update_state(y_batch, y_pred)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "model = MyFashionMNISTModel()\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.build(input_shape=[None, 28, 28])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MNIST 손글씨 분류 - Flatten Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 준비\n",
        "X = tf.keras.Input(shape=[28, 28])\n",
        "H = tf.keras.layers.Flatten()(X)\n",
        "H = tf.keras.layers.Dense(64, activation=\"swish\")(H)\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 준비합니다.\n",
        "X = tf.keras.Input(shape=[28, 28])\n",
        "H = tf.keras.layers.Flatten()(X)\n",
        "H = tf.keras.layers.Dense(64, activation=tf.keras.activations.swish)(H)\n",
        "Y = tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              metrics=tf.keras.metrics.sparse_categorical_accuracy)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=10, validation_split=0.1, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 시각화\n",
        "result = model.fit(x_train, y_train, epochs=10, validation_split=0.1, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(result.history['loss'])\n",
        "plt.plot(result.history['val_loss'])\n",
        "plt.legend(['loss','val_loss'])\n",
        "plt.show()\n",
        "\n",
        "plt.plot(result.history['sparse_categorical_accuracy'])\n",
        "plt.plot(result.history['val_sparse_categorical_accuracy'])\n",
        "plt.legend(['sparse_categorical_accuracy','val_sparse_categorical_accuracy'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 준비합니다.\n",
        "X = tf.keras.Input(shape=[28, 28])\n",
        "H = tf.keras.layers.Flatten()(X)\n",
        "H = tf.keras.layers.Dense(64, activation=tf.keras.activations.swish)(H)\n",
        "Y = tf.keras.layers.Dense(10, activation=tf.keras.activations.softmax)(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              # loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              # metrics=tf.keras.metrics.sparse_categorical_accuracy,\n",
        "              metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터로 모델을 학습합니다.\n",
        "result = model.fit(x_train, y_train, epochs=10, batch_size=128,\n",
        "          validation_split=0.2 # validation_data=(x_val, y_val)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "result = model.fit(x_train, y_train, epochs=100, batch_size=128,\n",
        "                   validation_split=0.2, # validation_data=(x_val, y_val)\n",
        "                   callbacks=[early]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 실습. CIFAR10 학습하기\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "# cifar10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"정답:\", y_train[0])\n",
        "plt.imshow(x_train[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델을 준비합니다.\n",
        "X = tf.keras.Input(shape=[32, 32, 3])\n",
        "H = tf.keras.layers.Flatten()(X)\n",
        "\n",
        "H = tf.keras.layers.Dense(32)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation('swish')(H)\n",
        "\n",
        "for i in range(32):\n",
        "    H1 = tf.keras.layers.Dropout(0.5)(H)\n",
        "    H1 = tf.keras.layers.Dense(32, activation=\"swish\")(H)\n",
        "    H1 = tf.keras.layers.BatchNormalization()(H1)\n",
        "    H = tf.keras.layers.Add()([H, H1])\n",
        "\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 16s 23ms/step - loss: 7.0083 - sparse_categorical_accuracy: 0.1723 - val_loss: 7.5692 - val_sparse_categorical_accuracy: 0.1315\n",
            "Epoch 2/100\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 3.4198 - sparse_categorical_accuracy: 0.2320 - val_loss: 3.7129 - val_sparse_categorical_accuracy: 0.2109\n",
            "Epoch 3/100\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 2.6350 - sparse_categorical_accuracy: 0.2653 - val_loss: 2.6605 - val_sparse_categorical_accuracy: 0.2540\n",
            "Epoch 4/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 2.3008 - sparse_categorical_accuracy: 0.2896 - val_loss: 2.4315 - val_sparse_categorical_accuracy: 0.2794\n",
            "Epoch 5/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 2.1241 - sparse_categorical_accuracy: 0.3054 - val_loss: 2.2081 - val_sparse_categorical_accuracy: 0.2998\n",
            "Epoch 6/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 2.0090 - sparse_categorical_accuracy: 0.3245 - val_loss: 2.0703 - val_sparse_categorical_accuracy: 0.3115\n",
            "Epoch 7/100\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 1.9359 - sparse_categorical_accuracy: 0.3346 - val_loss: 2.0142 - val_sparse_categorical_accuracy: 0.3244\n",
            "Epoch 8/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.8845 - sparse_categorical_accuracy: 0.3477 - val_loss: 1.9541 - val_sparse_categorical_accuracy: 0.3367\n",
            "Epoch 9/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.8378 - sparse_categorical_accuracy: 0.3583 - val_loss: 1.8994 - val_sparse_categorical_accuracy: 0.3523\n",
            "Epoch 10/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.8035 - sparse_categorical_accuracy: 0.3674 - val_loss: 1.8836 - val_sparse_categorical_accuracy: 0.3484\n",
            "Epoch 11/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.7699 - sparse_categorical_accuracy: 0.3766 - val_loss: 1.8570 - val_sparse_categorical_accuracy: 0.3656\n",
            "Epoch 12/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.7421 - sparse_categorical_accuracy: 0.3866 - val_loss: 1.8661 - val_sparse_categorical_accuracy: 0.3578\n",
            "Epoch 13/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.7195 - sparse_categorical_accuracy: 0.3917 - val_loss: 1.8024 - val_sparse_categorical_accuracy: 0.3730\n",
            "Epoch 14/100\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.6957 - sparse_categorical_accuracy: 0.3988 - val_loss: 1.7844 - val_sparse_categorical_accuracy: 0.3768\n",
            "Epoch 15/100\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.6758 - sparse_categorical_accuracy: 0.4068 - val_loss: 1.7899 - val_sparse_categorical_accuracy: 0.3798\n",
            "Epoch 16/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.6557 - sparse_categorical_accuracy: 0.4136 - val_loss: 1.7766 - val_sparse_categorical_accuracy: 0.3869\n",
            "Epoch 17/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.6397 - sparse_categorical_accuracy: 0.4192 - val_loss: 1.7643 - val_sparse_categorical_accuracy: 0.3851\n",
            "Epoch 18/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.6225 - sparse_categorical_accuracy: 0.4252 - val_loss: 1.7584 - val_sparse_categorical_accuracy: 0.3890\n",
            "Epoch 19/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5999 - sparse_categorical_accuracy: 0.4311 - val_loss: 1.7295 - val_sparse_categorical_accuracy: 0.4050\n",
            "Epoch 20/100\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 1.5837 - sparse_categorical_accuracy: 0.4366 - val_loss: 1.7479 - val_sparse_categorical_accuracy: 0.3918\n",
            "Epoch 21/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5693 - sparse_categorical_accuracy: 0.4429 - val_loss: 1.7183 - val_sparse_categorical_accuracy: 0.4093\n",
            "Epoch 22/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5548 - sparse_categorical_accuracy: 0.4486 - val_loss: 1.7070 - val_sparse_categorical_accuracy: 0.4070\n",
            "Epoch 23/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5390 - sparse_categorical_accuracy: 0.4534 - val_loss: 1.7295 - val_sparse_categorical_accuracy: 0.4032\n",
            "Epoch 24/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5260 - sparse_categorical_accuracy: 0.4564 - val_loss: 1.7640 - val_sparse_categorical_accuracy: 0.3903\n",
            "Epoch 25/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.5162 - sparse_categorical_accuracy: 0.4587 - val_loss: 1.7606 - val_sparse_categorical_accuracy: 0.4025\n",
            "Epoch 26/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.4990 - sparse_categorical_accuracy: 0.4683 - val_loss: 1.7113 - val_sparse_categorical_accuracy: 0.4060\n",
            "Epoch 27/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.4877 - sparse_categorical_accuracy: 0.4692 - val_loss: 1.6997 - val_sparse_categorical_accuracy: 0.4127\n",
            "Epoch 28/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.4748 - sparse_categorical_accuracy: 0.4754 - val_loss: 1.7220 - val_sparse_categorical_accuracy: 0.4125\n",
            "Epoch 29/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.4595 - sparse_categorical_accuracy: 0.4796 - val_loss: 1.7184 - val_sparse_categorical_accuracy: 0.4110\n",
            "Epoch 30/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.4521 - sparse_categorical_accuracy: 0.4834 - val_loss: 1.6753 - val_sparse_categorical_accuracy: 0.4252\n",
            "Epoch 31/100\n",
            "157/157 [==============================] - 3s 17ms/step - loss: 1.4420 - sparse_categorical_accuracy: 0.4875 - val_loss: 1.7292 - val_sparse_categorical_accuracy: 0.4149\n",
            "Epoch 32/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.4286 - sparse_categorical_accuracy: 0.4913 - val_loss: 1.7553 - val_sparse_categorical_accuracy: 0.3941\n",
            "Epoch 33/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.4178 - sparse_categorical_accuracy: 0.4943 - val_loss: 1.7088 - val_sparse_categorical_accuracy: 0.4134\n",
            "Epoch 34/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.4094 - sparse_categorical_accuracy: 0.4972 - val_loss: 1.7505 - val_sparse_categorical_accuracy: 0.4043\n",
            "Epoch 35/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.4005 - sparse_categorical_accuracy: 0.5012 - val_loss: 1.6803 - val_sparse_categorical_accuracy: 0.4226\n",
            "Epoch 36/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.3896 - sparse_categorical_accuracy: 0.5060 - val_loss: 1.7052 - val_sparse_categorical_accuracy: 0.4197\n",
            "Epoch 37/100\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 1.3770 - sparse_categorical_accuracy: 0.5108 - val_loss: 1.8296 - val_sparse_categorical_accuracy: 0.3987\n",
            "Epoch 38/100\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 1.3733 - sparse_categorical_accuracy: 0.5109 - val_loss: 1.7021 - val_sparse_categorical_accuracy: 0.4230\n",
            "Epoch 39/100\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 1.3628 - sparse_categorical_accuracy: 0.5152 - val_loss: 1.7268 - val_sparse_categorical_accuracy: 0.4082\n",
            "Epoch 40/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.3515 - sparse_categorical_accuracy: 0.5200 - val_loss: 1.6661 - val_sparse_categorical_accuracy: 0.4287\n",
            "Epoch 41/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.3423 - sparse_categorical_accuracy: 0.5208 - val_loss: 1.7256 - val_sparse_categorical_accuracy: 0.4119\n",
            "Epoch 42/100\n",
            "157/157 [==============================] - 3s 18ms/step - loss: 1.3382 - sparse_categorical_accuracy: 0.5239 - val_loss: 1.7122 - val_sparse_categorical_accuracy: 0.4268\n",
            "Epoch 43/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.3271 - sparse_categorical_accuracy: 0.5269 - val_loss: 1.8202 - val_sparse_categorical_accuracy: 0.3950\n",
            "Epoch 44/100\n",
            "157/157 [==============================] - 3s 20ms/step - loss: 1.3218 - sparse_categorical_accuracy: 0.5273 - val_loss: 1.6874 - val_sparse_categorical_accuracy: 0.4288\n",
            "Epoch 45/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.3112 - sparse_categorical_accuracy: 0.5330 - val_loss: 1.8191 - val_sparse_categorical_accuracy: 0.4029\n",
            "Epoch 46/100\n",
            "157/157 [==============================] - 3s 19ms/step - loss: 1.3032 - sparse_categorical_accuracy: 0.5359 - val_loss: 1.6818 - val_sparse_categorical_accuracy: 0.4313\n",
            "Epoch 47/100\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 1.2978 - sparse_categorical_accuracy: 0.5373 - val_loss: 1.7190 - val_sparse_categorical_accuracy: 0.4214\n",
            "Epoch 48/100\n",
            "157/157 [==============================] - 4s 24ms/step - loss: 1.2875 - sparse_categorical_accuracy: 0.5401 - val_loss: 1.6877 - val_sparse_categorical_accuracy: 0.4307\n",
            "Epoch 49/100\n",
            "157/157 [==============================] - 4s 22ms/step - loss: 1.2787 - sparse_categorical_accuracy: 0.5441 - val_loss: 1.6794 - val_sparse_categorical_accuracy: 0.4329\n",
            "Epoch 50/100\n",
            "157/157 [==============================] - 3s 21ms/step - loss: 1.2791 - sparse_categorical_accuracy: 0.5456 - val_loss: 1.7288 - val_sparse_categorical_accuracy: 0.4185\n"
          ]
        }
      ],
      "source": [
        "early = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True) # 오버피팅이 10번 관측되면 멈추고, 여태 나온 최고 성능으로 모델을 만들어라\n",
        "result = model.fit(x_train, y_train, epochs=100, batch_size=256,\n",
        "                   validation_split=0.2, # validation_data=(x_val, y_val) <- 만약 검증용 데이터셋이 있으면 이렇게 넣어라\n",
        "                   callbacks=[early]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vy5qoZ2qNYrA"
      },
      "source": [
        "## MNIST 손글씨 분류 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg4jIxttwp2O"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej9cxgo4Nekh"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0cPSDRZNwxL"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "H = tf.keras.layers.Conv2D(3, kernel_size=5, activation='swish')(X)\n",
        "H = tf.keras.layers.Conv2D(6, kernel_size=5, activation='swish')(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wRFFDeBN257"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6OF74HLN3gF"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "model.evaluate(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF0EwPHwAOmZ"
      },
      "outputs": [],
      "source": [
        "pip install gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9O8sgC3AOiV"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "\n",
        "def greet(s_img):\n",
        "    # 흑백으로 변환\n",
        "    s_img = s_img.convert('L')\n",
        "\n",
        "    # 크기를 변경\n",
        "    img = s_img.resize((28, 28))\n",
        "\n",
        "    # 다시 numpy array로 변환\n",
        "    img = np.full((28, 28), 255.) - np.array(img)\n",
        "\n",
        "    return model.predict(img.reshape(1, 28, 28)), s_img\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=greet,\n",
        "    inputs=gr.Image(source=\"canvas\", type=\"pil\"),\n",
        "    outputs=[\"text\", \"image\"]\n",
        ")\n",
        "demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkiCgBS3XzqP"
      },
      "source": [
        "## MNIST 손글씨 분류 - MaxPool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCMXPDtxN44-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dA-OA3kX77h"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "y_train = pd.get_dummies(y_train)\n",
        "y_test = pd.get_dummies(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00-OP8p9X9k6"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "H = tf.keras.layers.Conv2D(3, 5, activation='swish')(X)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(6, 5, activation='swish')(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(84, activation='swish')(H)\n",
        "Y = tf.keras.layers.Dense(10, activation='softmax')(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXlmYTmOYemO"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNVV-74L19f7"
      },
      "source": [
        "### 클래스 속성 vs 메쏘드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuB395Ukb8Mr"
      },
      "outputs": [],
      "source": [
        "class Animal:\n",
        "    def __init__(self, name, type):\n",
        "        self.name = name\n",
        "        self.type = type\n",
        "\n",
        "    def cry(self):\n",
        "        if self.type == \"고양이\":\n",
        "            return \"야옹\"\n",
        "        elif self.type == \"개\":\n",
        "            return \"멍멍\"\n",
        "\n",
        "a = Animal(\"키키\", \"개\")\n",
        "b = Animal(\"지지\", \"고양이\")\n",
        "\n",
        "print(a.cry())\n",
        "print(b.cry())\n",
        "print(a.name, a.type)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame([[1, 2, 3], [4, 5, 6]])\n",
        "print(df.shape)\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhenEMxn8iNC"
      },
      "source": [
        "# CNN Models - LeNet5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MHkbH7ucZmg"
      },
      "source": [
        "## fashion mnist - 실습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouGq3_nK2DKU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiGlC-Cybkhf"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaRvMbiGbsmG"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "num = 1\n",
        "print(y_train[num])\n",
        "plt.imshow(x_train[num], cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgQ2VWFd1Dqi"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "# 텐서플로우의 원핫인코딩 함수\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_ZxYZD52LZe"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "H = tf.keras.layers.Conv2D(3, 5, activation=\"swish\")(X)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(6, 5, activation=\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "H = tf.keras.layers.Dense(128, activation=\"swish\")(H)\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-D4H_Ola3JCC"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyNCmytR3J1o"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCrE0h778J5a"
      },
      "source": [
        "## LeNet-5 + fashion mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-7mr_qxCmFO"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "# 텐서플로우의 원핫인코딩 함수\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)\n",
        "\n",
        "y_train[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kn_MHtXp3LCr"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[28, 28, 1])\n",
        "\n",
        "H = tf.keras.layers.Conv2D(6, 5, padding=\"same\")(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Conv2D(16, 5)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(120)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(84)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKQu5Yg28pVH"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53cumPp09C-6"
      },
      "outputs": [],
      "source": [
        "# 모델 평가\n",
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-E-uTEBwFJ"
      },
      "source": [
        "## Lenet-5 + cifar10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKVAh5uy9RrU"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# 텐서플로우의 원핫인코딩 함수\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb0lYLGQB2mP"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[32, 32, 3])\n",
        "\n",
        "H = tf.keras.layers.Conv2D(6, 5)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Conv2D(16, 5)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "H = tf.keras.layers.MaxPool2D()(H)\n",
        "\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(120)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(84)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_KOw6aeCLqj"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxyFMSGvMq-p"
      },
      "source": [
        "## Lenet-5 + cifar10 + dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8tokzHLCPPe"
      },
      "outputs": [],
      "source": [
        "# 데이터 준비\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# normalize\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# 텐서플로우의 원핫인코딩 함수\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vDRiRlggM5xs"
      },
      "outputs": [],
      "source": [
        "# 모델 생성\n",
        "X = tf.keras.Input(shape=[32, 32, 3])\n",
        "\n",
        "H = tf.keras.layers.Conv2D(6, 5)(X)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "# H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(6, 5, strides=2, padding=\"same\")(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Conv2D(16, 5)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "# H = tf.keras.layers.MaxPool2D()(H)\n",
        "H = tf.keras.layers.Conv2D(16, 5, strides=2, padding=\"same\")(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Flatten()(H)\n",
        "\n",
        "H = tf.keras.layers.Dropout(0.6)(H)\n",
        "H = tf.keras.layers.Dense(120)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "H = tf.keras.layers.Dense(84)(H)\n",
        "H = tf.keras.layers.BatchNormalization()(H)\n",
        "H = tf.keras.layers.Activation(\"swish\")(H)\n",
        "\n",
        "Y = tf.keras.layers.Dense(10, activation=\"softmax\")(H)\n",
        "\n",
        "model = tf.keras.Model(X, Y)\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=\"accuracy\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV1sXf8sNKxk"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "es = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "model.fit(x_train, y_train, epochs=100000, batch_size=128, validation_split=0.1, callbacks=[es])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezFWHTskVBIP"
      },
      "source": [
        "## Data Augmentation\n",
        "- 256x256 이미지 10,000장을 학습용 이미지로 제공\n",
        "- 224x224로 crop 하여 1장의 이미지에서 1024 이미지를 추출\n",
        "- 좌우반전을 더해 총 2048만 장의 이미지로 학습을 하게 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVLkaNNHVA2i"
      },
      "outputs": [],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=False,\n",
        "    rotation_range=0.1,\n",
        ")\n",
        "train_ds = datagen.flow(x_train[:40000], y_train[:40000], batch_size=128)\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((x_train[40000:], y_train[40000:])).batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC21T2lANQpA"
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(train_ds))\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHzMVg53YXiL"
      },
      "outputs": [],
      "source": [
        "# 모델 학습\n",
        "es = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
        "model.fit(train_ds, validation_data=valid_ds, epochs=100000, callbacks=[es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs77xTTIZS2U"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PelELvulPz1f"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
