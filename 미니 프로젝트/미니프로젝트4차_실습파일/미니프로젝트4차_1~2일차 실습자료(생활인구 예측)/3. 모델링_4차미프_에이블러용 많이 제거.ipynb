{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22f7625f",
   "metadata": {},
   "source": [
    "# 안녕하세요^^ \n",
    "# AIVLE 미니 프로젝트에 오신 여러분을 환영합니다.\n",
    "* 본 과정에서는 실제 사례와 데이터를 기반으로 문제를 해결하는 전체 과정을 자기 주도형 실습으로 진행해볼 예정입니다.\n",
    "* 앞선 교육과정을 정리하는 마음과 지금까지 배운 내용을 바탕으로 문제 해결을 해볼게요!\n",
    "* 미니 프로젝트를 통한 문제 해결 과정 'A에서 Z까지', 지금부터 시작합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b1edbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-stress",
   "metadata": {},
   "source": [
    "# (실습준비) 데이터 불러오기부터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9744eae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 로딩\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# 시각화 한글폰트 설정\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "sns.set(font=\"Malgun Gothic\",#\"NanumGothicCoding\", \n",
    "        rc={\"axes.unicode_minus\":False}, # 마이너스 부호 깨짐 현상 해결\n",
    "        style='darkgrid')\n",
    "\n",
    "# 경고 메시지 숨기기\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터 로딩\n",
    "train_x = pd.read_csv('../data/train_x.csv')\n",
    "train_y = pd.read_csv('../data/train_y.csv')\n",
    "\n",
    "# 평가 데이터 로딩\n",
    "test_x = pd.read_csv('../data/test_x.csv')\n",
    "test_y = pd.read_csv('../data/test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a4b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_x.tail(2))\n",
    "display(train_y.tail(2))\n",
    "display(test_x.tail(2))\n",
    "display(test_y.tail(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2084ca1a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-expansion",
   "metadata": {},
   "source": [
    "# 1. Machine Learning\n",
    "## 이제 모델링을 해봅시다!\n",
    "+ KeyPoint : 머신러닝 라이브러리를 토대로 모델링을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-brighton",
   "metadata": {},
   "source": [
    "### 가. LinearRegression 부터 시작해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-client",
   "metadata": {},
   "source": [
    "#### [실습문제1] 머신러닝_1\n",
    "* Train과 Test로 나눈 데이터를 기준으로 LinearRegression 모델링을 진행하고 평가를 해주세요.\n",
    "* 성능지표 : RMSE, R-squared Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-disclaimer",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Linear Regression 모델 생성 및 학습\n",
    "model1 = LinearRegression()\n",
    "model1.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = model1.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-universe",
   "metadata": {},
   "source": [
    "### 나. 다음은 앙상블 기법을 토대로 랜덤포레스트와 그라디언부스팅을 활용해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-escape",
   "metadata": {},
   "source": [
    "#### 1) 렌덤포레스트\n",
    "##### 배깅의 일종으로 의사결정나무(Decision Tree) 여러 개를 모아서 숲을 랜덤으로 구성하고 이를 종합해서 최종 모델을 산출하는 기법이라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-eleven",
   "metadata": {},
   "source": [
    "#### [실습문제2] 머신러닝_2\n",
    "* Train과 Test로 나눈 데이터를 기준으로 렌덤포레스트로 모델을 학습을 진행하고 평가를 해주세요.\n",
    "* 성능지표 : RMSE, R-squared Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하세요.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest 모델 생성 및 학습\n",
    "model2 = RandomForestRegressor(random_state=1234)\n",
    "model2.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = model2.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788be2bb",
   "metadata": {},
   "source": [
    "#### [실습문제3] 머신러닝_3\n",
    "* 렌덤포레스트로 학습한 모델의 feature_importances 또는 Shap value를 구해보세요.\n",
    "* 확인할 수 있는 내용으로 우리 모델에서의 인사이트를 정리해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19f84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature의 중요도 확인\n",
    "# Feature Importances 확인\n",
    "feature_importances = model2.feature_importances_\n",
    "\n",
    "# 각 특성의 중요도를 DataFrame으로 정리\n",
    "feature_importance_df = pd.DataFrame({'Feature': train_x.columns, 'Importance': feature_importances})\n",
    "\n",
    "# 중요도로 내림차순 정렬\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# 중요도를 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7989f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인할 수 있는 인사이트\n",
    "# 1.\n",
    "# 2.\n",
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-vocabulary",
   "metadata": {},
   "source": [
    "#### 2) GradientBoosting\n",
    "##### 앞선 모델의 에러를 다음 모델의 예측 값으로 활용하면서 가중치 업데이트 하는데 경사하강법(Gradient Descent)를 활용해서 최적 모델을 만드는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-google",
   "metadata": {},
   "source": [
    "#### [실습문제4] 머신러닝_4\n",
    "* Train과 Test로 나눈 데이터를 기준으로 그라디언트부스팅으로 모델을 학습을 진행하고 평가를 해주세요.\n",
    "* 성능지표 : RMSE, R-squared Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Gradient Boosting 모델 생성 및 학습\n",
    "model3 = GradientBoostingRegressor(random_state=1234)\n",
    "model3.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = model3.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04925b45",
   "metadata": {},
   "source": [
    "#### [실습문제5] 머신러닝_5\n",
    "* 그라디언트부스팅으로 학습한 모델의 feature_importances 또는 Shap value를 구해보세요.\n",
    "* 확인할 수 있는 내용으로 우리 모델에서의 인사이트를 정리해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8deba58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature Importances 확인\n",
    "feature_importances = model3.feature_importances_\n",
    "\n",
    "# 각 특성의 중요도를 DataFrame으로 정리\n",
    "feature_importance_df = pd.DataFrame({'Feature': train_x.columns, 'Importance': feature_importances})\n",
    "\n",
    "# 중요도로 내림차순 정렬\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# 중요도를 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1bfe7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인할 수 있는 인사이트\n",
    "# 1.\n",
    "# 2.\n",
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b38e1a",
   "metadata": {},
   "source": [
    "#### [실습문제8] 스케일링\n",
    "* Min Max Scale 함수를 활용하여 스케일링 후 위 모델에 적용하여 보세요. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ac8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "ls = train_x.columns\n",
    "\n",
    "train_x[ls] = scaler.fit_transform(train_x[ls])\n",
    "test_x[ls] = scaler.transform(test_x[ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b96ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(train_x.head())\n",
    "display(test_x.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d698fd",
   "metadata": {},
   "source": [
    "### 가. LinearRegression 부터 시작해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebac92f",
   "metadata": {},
   "source": [
    "#### [실습문제1] 머신러닝_1\n",
    "* Train과 Test로 나눈 데이터를 기준으로 LinearRegression 모델링을 진행하고 평가를 해주세요.\n",
    "* 성능지표 : RMSE, R-squared Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ab64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Linear Regression 모델 생성 및 학습\n",
    "model1 = LinearRegression()\n",
    "model1.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = model1.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9442d04",
   "metadata": {},
   "source": [
    "### 나. 다음은 앙상블 기법을 토대로 랜덤포레스트와 그라디언부스팅을 활용해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33afd772",
   "metadata": {},
   "source": [
    "#### 1) 렌덤포레스트\n",
    "##### 배깅의 일종으로 의사결정나무(Decision Tree) 여러 개를 모아서 숲을 랜덤으로 구성하고 이를 종합해서 최종 모델을 산출하는 기법이라고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7ab7c1",
   "metadata": {},
   "source": [
    "#### [실습문제2] 머신러닝_2\n",
    "* Train과 Test로 나눈 데이터를 기준으로 렌덤포레스트로 모델을 학습을 진행하고 평가를 해주세요.\n",
    "* 성능지표 : RMSE, R-squared Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7a4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래에 실습코드를 작성하세요.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest 모델 생성 및 학습\n",
    "model2 = RandomForestRegressor(random_state=1234)\n",
    "model2.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = model2.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4370ffc",
   "metadata": {},
   "source": [
    "#### [실습문제3] 머신러닝_3\n",
    "* 렌덤포레스트로 학습한 모델의 feature_importances 또는 Shap value를 구해보세요.\n",
    "* 확인할 수 있는 내용으로 우리 모델에서의 인사이트를 정리해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature의 중요도 확인\n",
    "# Feature Importances 확인\n",
    "feature_importances = model2.feature_importances_\n",
    "\n",
    "# 각 특성의 중요도를 DataFrame으로 정리\n",
    "feature_importance_df = pd.DataFrame({'Feature': train_x.columns, 'Importance': feature_importances})\n",
    "\n",
    "# 중요도로 내림차순 정렬\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# 중요도를 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "print( feature_importance_df.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b8d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 확인할 수 있는 인사이트\n",
    "# 1.\n",
    "# 2.\n",
    "# 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf1914",
   "metadata": {},
   "source": [
    "#### 2) GradientBoosting\n",
    "##### 앞선 모델의 에러를 다음 모델의 예측 값으로 활용하면서 가중치 업데이트 하는데 경사하강법(Gradient Descent)를 활용해서 최적 모델을 만드는 기법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b32a671",
   "metadata": {},
   "source": [
    "#### [실습문제4] 머신러닝_4\n",
    "* Train과 Test로 나눈 데이터를 기준으로 그라디언트부스팅으로 모델을 학습을 진행하고 평가를 해주세요.\n",
    "* 성능지표 : RMSE, R-squared Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264f92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Gradient Boosting 모델 생성 및 학습\n",
    "model3 = GradientBoostingRegressor(random_state=1234)\n",
    "model3.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = model3.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9586a2b",
   "metadata": {},
   "source": [
    "#### [실습문제5] 머신러닝_5\n",
    "* 그라디언트부스팅으로 학습한 모델의 feature_importances 또는 Shap value를 구해보세요.\n",
    "* 확인할 수 있는 내용으로 우리 모델에서의 인사이트를 정리해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importances 확인\n",
    "feature_importances = model3.feature_importances_\n",
    "\n",
    "# 각 특성의 중요도를 DataFrame으로 정리\n",
    "feature_importance_df = pd.DataFrame({'Feature': train_x.columns, 'Importance': feature_importances})\n",
    "\n",
    "# 중요도로 내림차순 정렬\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# 중요도를 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "print(feature_importance_df.sort_values(by='Importance', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd12d46",
   "metadata": {},
   "source": [
    "#### 3) Elastic Net\n",
    "##### 엘라스틱 넷은 L1(Lasso) 및 L2(Ridge) 규제를 결합한 모델로, 두 규제의 장점을 모두 가지며 데이터에 대한 유연한 모델을 생성할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f643fce",
   "metadata": {},
   "source": [
    "#### [실습문제6] 머신러닝_6\n",
    "* Train과 Test로 나눈 데이터를 기준으로 엘리스틱넷 모델을 학습을 진행하고 평가를 해주세요.\n",
    "* 성능지표 : RMSE, R-squared Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# ElasticNet 모델 생성 및 학습\n",
    "elastic_net = ElasticNet(alpha=0.8, l1_ratio=1)\n",
    "elastic_net.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = elastic_net.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af7758",
   "metadata": {},
   "source": [
    "### 라쏘 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36284e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Lasso 모델 생성 및 학습\n",
    "lasso = Lasso(alpha=0.9)  # alpha 값은 규제 강도를 나타냅니다\n",
    "lasso.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = lasso.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610f6652",
   "metadata": {},
   "source": [
    "### 서포트 벡터 머신 회귀 (Support Vector Machine Regression) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a400a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# SVM 회귀 모델 생성 및 학습\n",
    "svm_regressor = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "svm_regressor.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = svm_regressor.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d92614",
   "metadata": {},
   "source": [
    "### 인공 신경망 회귀 (Neural Network Regression) 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d947d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# 신경망 회귀 모델 생성 및 학습\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', alpha=0.0001, max_iter=1000, random_state=42)\n",
    "mlp_regressor.fit(train_x, train_y)\n",
    "\n",
    "# 모델을 사용하여 평가 데이터에 대한 예측 생성\n",
    "test_y_pred = mlp_regressor.predict(test_x)\n",
    "\n",
    "# RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(test_y, test_y_pred))\n",
    "\n",
    "# R-squared Score 계산\n",
    "r2 = r2_score(test_y, test_y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f054fd75",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-optics",
   "metadata": {},
   "source": [
    "# 2. Deep Learning \n",
    "## 이번엔 딥러닝 모델링을 해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-dealer",
   "metadata": {},
   "source": [
    "#### [실습문제9] 딥러닝\n",
    "\n",
    "* tensorflow 라이브러리를 활용한 모델을 자유롭게 만들어보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacebee1",
   "metadata": {},
   "source": [
    "### 1번 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb331b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "input_shape = train_x.shape[1]\n",
    "# 모델 생성\n",
    "deep_model1 = keras.Sequential([\n",
    "    layers.Input(shape=(input_shape)),  # 입력층\n",
    "    layers.Dense(128, activation='relu'),  # 은닉층 1\n",
    "    layers.Dense(64, activation='relu'),   # 은닉층 2\n",
    "    layers.Dense(1, activation='linear')  # 출력층\n",
    "])\n",
    "\n",
    "# Early Stopping 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 모니터링할 지표 (검증 데이터의 손실 함수)\n",
    "    patience=10,  # 지정된 지표가 개선되지 않은 에폭 수\n",
    "    restore_best_weights=True  # 최적의 모델 가중치로 복원\n",
    ")\n",
    "\n",
    "# 모델 컴파일\n",
    "deep_model1.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "deep_model1.summary()\n",
    "deep_model1.fit(train_x, train_y, batch_size=64, epochs=50, validation_data=(test_x, test_y), callbacks=[early_stopping])\n",
    "\n",
    "deep_pred1 = deep_model1.predict(test_x)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, deep_pred1))\n",
    "mae = mean_absolute_error(test_y, deep_pred1)\n",
    "r2 = r2_score(test_y, deep_pred1)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b7df7",
   "metadata": {},
   "source": [
    "### 2번 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dce4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x.shape[1]\n",
    "# 모델 생성\n",
    "deep_model2 = keras.Sequential([\n",
    "    layers.Input(shape=(input_shape)),  # 입력층\n",
    "    layers.Dense(128, activation='relu'),  # 은닉층 1\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),   # 은닉층 2\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation='linear')  # 출력층\n",
    "])\n",
    "\n",
    "# Early Stopping 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 모니터링할 지표 (검증 데이터의 손실 함수)\n",
    "    patience=10,  # 지정된 지표가 개선되지 않은 에폭 수\n",
    "    restore_best_weights=True  # 최적의 모델 가중치로 복원\n",
    ")\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "deep_model2.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "deep_model2.summary()\n",
    "\n",
    "# 모델 학습\n",
    "deep_model2.fit(train_x, train_y, batch_size=64, epochs=50, validation_data=(test_x, test_y), callbacks=[early_stopping])\n",
    "\n",
    "deep_pred2 = deep_model2.predict(test_x)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, deep_pred2))\n",
    "mae = mean_absolute_error(test_y, deep_pred2)\n",
    "r2 = r2_score(test_y, deep_pred2)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4ce12",
   "metadata": {},
   "source": [
    "### 3번 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4fee2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x.shape[1]\n",
    "# 모델 생성\n",
    "deep_model3 = keras.Sequential([\n",
    "    layers.Input(shape=(input_shape)),  # 입력층\n",
    "    layers.Dense(128, activation='tanh'),  # 은닉층 1\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='tanh'),   # 은닉층 2\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(32, activation='tanh'),   # 은닉층 2\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation='linear')  # 출력층\n",
    "])\n",
    "\n",
    "# Early Stopping 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 모니터링할 지표 (검증 데이터의 손실 함수)\n",
    "    patience=10,  # 지정된 지표가 개선되지 않은 에폭 수\n",
    "    restore_best_weights=True  # 최적의 모델 가중치로 복원\n",
    ")\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.05)\n",
    "deep_model3.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "deep_model3.summary()\n",
    "\n",
    "# 모델 학습\n",
    "deep_model3.fit(train_x, train_y, batch_size=32, epochs=100, validation_data=(test_x, test_y), callbacks=[early_stopping])\n",
    "\n",
    "deep_pred3 = deep_model3.predict(test_x)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, deep_pred3))\n",
    "mae = mean_absolute_error(test_y, deep_pred3)\n",
    "r2 = r2_score(test_y, deep_pred3)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7edddf",
   "metadata": {},
   "source": [
    "### 4번 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd389f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x.shape[1]\n",
    "# 모델 생성\n",
    "deep_model4 = keras.Sequential([\n",
    "    layers.Input(shape=(input_shape)),  # 입력층\n",
    "    layers.Dense(128, activation='tanh'),  # 은닉층 1\n",
    "    layers.Dense(128, activation='tanh'),  # 은닉층 1\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),   # 은닉층 2\n",
    "    layers.Dense(64, activation='relu'),   # 은닉층 2\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(32, activation='relu'),   # 은닉층 2\n",
    "    layers.Dense(32, activation='relu'),   # 은닉층 2\n",
    "    layers.Dropout(0.5),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(1, activation='linear')  # 출력층\n",
    "])\n",
    "\n",
    "# Early Stopping 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 모니터링할 지표 (검증 데이터의 손실 함수)\n",
    "    patience=10,  # 지정된 지표가 개선되지 않은 에폭 수\n",
    "    restore_best_weights=True  # 최적의 모델 가중치로 복원\n",
    ")\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "deep_model4.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "deep_model4.summary()\n",
    "\n",
    "# 모델 학습\n",
    "deep_model4.fit(train_x, train_y, batch_size=64, epochs=100, validation_data=(test_x, test_y), callbacks=[early_stopping])\n",
    "\n",
    "deep_pred4 = deep_model4.predict(test_x)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, deep_pred4))\n",
    "mae = mean_absolute_error(test_y, deep_pred4)\n",
    "r2 = r2_score(test_y, deep_pred4)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de498d4",
   "metadata": {},
   "source": [
    "### 모델5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0096f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_x.shape[1]\n",
    "# 모델 생성\n",
    "deep_model5 = keras.Sequential([\n",
    "    layers.Input(shape=(input_shape)),  # 입력층\n",
    "    layers.Dense(128, activation='relu'),  # 은닉층 1\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(64, activation='relu'),   # 은닉층 2\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(32, activation='relu'),   # 은닉층 2\n",
    "    layers.Dropout(0.2),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(6, activation='relu'),   # 은닉층 2\n",
    "    layers.Dense(1, activation='linear')  # 출력층\n",
    "])\n",
    "\n",
    "# Early Stopping 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 모니터링할 지표 (검증 데이터의 손실 함수)\n",
    "    patience=10,  # 지정된 지표가 개선되지 않은 에폭 수\n",
    "    restore_best_weights=True  # 최적의 모델 가중치로 복원\n",
    ")\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "deep_model5.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "deep_model5.summary()\n",
    "\n",
    "# 모델 학습\n",
    "deep_model5.fit(train_x, train_y, batch_size=64, epochs=100, validation_data=(test_x, test_y), callbacks=[early_stopping])\n",
    "\n",
    "deep_pred5 = deep_model5.predict(test_x)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, deep_pred5))\n",
    "mae = mean_absolute_error(test_y, deep_pred5)\n",
    "r2 = r2_score(test_y, deep_pred5)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"R-squared Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0bfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
